{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from green_city.utils import span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(s):\n",
    "    new_name = (s\n",
    "        .lower()\n",
    "        .replace(' ', '_')\n",
    "        .replace('[', '')\n",
    "        .replace(']', '')\n",
    "        .replace('/', '_')\n",
    "        .replace('relative_humidity_%', 'hum')\n",
    "        .replace('_kw', '_kW')\n",
    "        .replace('_w', '_W')\n",
    "        .replace('prediction', 'pred')\n",
    "        .replace('temperature_c', 'temp')\n",
    "        .replace('radiation_', '')\n",
    "        .replace('drybulb_', '')\n",
    "        .replace('_status', '')\n",
    "        .replace('6h_pred', 'pred_6h')\n",
    "        .replace('12h_pred', 'pred_12h')\n",
    "        .replace('24h_pred', 'pred_24h')\n",
    "        .replace('average_unmet_cooling_setpoint_difference_c', 'avg_unmet_cooling_temp') #do we even need this column?\n",
    "    )\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_nrs = [4, 5]\n",
    "\n",
    "for building_nr in building_nrs:\n",
    "    #1. load json for this building\n",
    "    with open(\"../data/citylearn_challenge_2021/schema.json\") as schema_file:\n",
    "        schema = json.load(schema_file)\n",
    "\n",
    "    building_properties = schema['buildings'][f'Building_{building_nr}']\n",
    "    pv_nominal_power_kW = building_properties['pv']['attributes']['nominal_power']\n",
    "\n",
    "    weather = pd.read_csv(\"../data/citylearn_challenge_2021/weather.csv\")\n",
    "    building = pd.read_csv(f\"../data/citylearn_challenge_2021/Building_{building_nr}.csv\")\n",
    "    building = pd.concat([building, weather], axis=1)\n",
    "    assert len(building) == len(weather)\n",
    "\n",
    "    building = (building\n",
    "    .drop(columns=[\"Heating Load [kWh]\"])\n",
    "    .assign(\n",
    "            datetime = span('2008-01-02', '2011-12-31'),\n",
    "            holiday = lambda x: x[\"Day Type\"] == 8)\n",
    "    .assign(workday = lambda x: (x.datetime.dt.weekday >= 1) & (x.datetime.dt.weekday <= 5) & (x[\"Day Type\"] != 8) )\n",
    "    .drop(columns=[\"Month\", \"Hour\", \"Day Type\"])\n",
    "    .set_index(\"datetime\")\n",
    "    .rename(columns=rename_cols)\n",
    "    .assign(solar_generation_kW = lambda x: x.solar_generation_W_kW * pv_nominal_power_kW/1000)\n",
    "    )\n",
    "    ##### heat pump electric consumption\n",
    "    eta_hpc = 0.15; # technical efficiency coefficient 0.2 ... 0.3 typically\n",
    "    temp_target_c = 5; # target temperature for hp cooling, typically 7 ... 10 °C, this equals approx. the temperature of the chilled water storage\n",
    "    T_th = 273.15; # thermodynamic temperature in Kelvin [K] corresponding to 0 °C \n",
    "    cop_c = eta_hpc * (temp_target_c + T_th)/ ((building['outdoor_temp'] + T_th) - (temp_target_c + T_th)) \n",
    "    # Calculate the electric energy consumption of the hp for cooling\n",
    "    building['electric_load_hp_kWh'] = round(building['cooling_load_kWh'] / cop_c,3) # add a column with the electric consumption [kW]\n",
    "    \n",
    "    building['net_load_kWh'] = building['equipment_electric_power_kWh'] + building['dhw_heating_kWh'] + building['electric_load_hp_kWh'] - building['solar_generation_kWh']\n",
    "    \n",
    "    building.to_csv(f\"../data/preprocessed/Building_{building_nr}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all buildings csv files for columns containing nan's or only single values (such as 0's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_buildings():\n",
    "    col_str = lambda x: x if (len(x) == 1 or any([np.isnan(val) for val in x])) else \"\"\n",
    "    unique_entries = {}\n",
    "    for building_nr in range(1, 10):\n",
    "        df = pd.read_csv(f\"../data/citylearn_challenge_2021/Building_{building_nr}.csv\")\n",
    "        assert df.shape == (35040, 12)\n",
    "        unique_entries[building_nr] = pd.Series({col: col_str(df[col].unique()) for col in df.columns})\n",
    "    print(\"all building's csv files are of shape (35040, 12).\")\n",
    "        \n",
    "    comparison_df = pd.DataFrame(unique_entries.values(), index=unique_entries.keys())\n",
    "    \n",
    "    return comparison_df\n",
    "        \n",
    "analyze_all_buildings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfe3b40481fecf67d20992515088cc989ac588a9d8e92be970fb8187427b4467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
