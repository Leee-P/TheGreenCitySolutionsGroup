{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from green_city.utils import index2datetime\n",
    "from green_city.regression import plot_ts, error_metrics, train_test_time_split\n",
    "from green_city.regression import seasons, time_of_day, forecast_dates\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_nr = \"all\"\n",
    "column_to_predict = \"net_load_kWh\"\n",
    "\n",
    "#document wide parameters that don't change in experiments\n",
    "#for logging to mlflow server\n",
    "global_params = {\n",
    "    \"building_nr\": building_nr,\n",
    "    \"predicted_feature\": column_to_predict,\n",
    "    \"resolution\": \"daily\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set write_date to True for logging to mlflow and SQL database\n",
    "write_data = False\n",
    "\n",
    "if write_data:\n",
    "    \n",
    "    # ## MLFLOW ##\n",
    "    import mlflow\n",
    "    from green_city.mlflow_config import get_mlflow_config\n",
    "\n",
    "    flow_conf = get_mlflow_config()\n",
    "    tracking_uri = flow_conf[\"TRACKING_URI\"]\n",
    "    mlflow.set_tracking_uri(flow_conf[\"TRACKING_URI\"])\n",
    "    mlflow.set_experiment(flow_conf[\"EXPERIMENT_NAME\"]);\n",
    "    \n",
    "\n",
    "    # ## DB CONNECTION ##\n",
    "    from sqlalchemy import create_engine\n",
    "    from decouple import Config, RepositoryEnv\n",
    "\n",
    "    config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "    db_connection_credentials = {\n",
    "        \"database\": config('POSTGRES_DB'),\n",
    "        \"user\": config('POSTGRES_USER'),\n",
    "        \"password\": config('POSTGRES_PASSWORD'),\n",
    "        \"host\": config('POSTGRES_HOST'),\n",
    "        \"port\": config('POSTGRES_PORT'),\n",
    "    }\n",
    "    DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "    db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if building_nr == 'all':\n",
    "    df = pd.read_csv(f\"../data/preprocessed/Agg_buildings.csv\").astype({'datetime': 'datetime64'}).set_index('datetime')\n",
    "else:\n",
    "    df = pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\").astype({'datetime': 'datetime64'}).set_index('datetime')\n",
    "df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional columns for time\n",
    "df['hour'] = df.index.hour.astype('category')\n",
    "df['month'] = df.index.month.astype('category')\n",
    "df['year'] = df.index.year.astype('category')\n",
    "df['holiday'] = df['holiday'].astype('category')\n",
    "df['workday'] = df['workday'].astype('category')\n",
    "\n",
    "df['season'] = df['month'].apply(seasons).astype('category')\n",
    "df['time_of_day'] = df['hour'].apply(time_of_day).astype('category')\n",
    "df['day_of_week'] = df.index.day_of_week.astype('category')\n",
    "\n",
    "# Creating lag variables\n",
    "for i in range(24):\n",
    "    df['net_load_kW_lag'+str(i+1)] = df['net_load_kW'].shift(i+1)\n",
    "df['net_load_kW_lag168'] = df['net_load_kW'].shift(24*7)\n",
    "\n",
    "# Exogenous variables for yearly, weekly and hourly seasonality\n",
    "df['year_sin365'] = np.sin(2 * np.pi * df.index.dayofyear / 365)\n",
    "df['year_cos365'] = np.cos(2 * np.pi * df.index.dayofyear / 365)\n",
    "df['year_sin365_2'] = np.sin(4 * np.pi * df.index.dayofyear / 365)\n",
    "df['year_cos365_2'] = np.cos(4 * np.pi * df.index.dayofyear / 365)\n",
    "df['week_sin365'] = np.sin(2 * np.pi * df.index.dayofweek/7)\n",
    "df['week_cos365'] = np.cos(2 * np.pi * df.index.dayofweek/7)\n",
    "df['week_sin365_2'] = np.sin(4 * np.pi * df.index.dayofweek/7)\n",
    "df['week_cos365_2'] = np.cos(4 * np.pi * df.index.dayofweek/7)\n",
    "df['hour_sin365'] = np.sin(2 * np.pi * df.index.hour/24)\n",
    "df['hour_cos365'] = np.cos(2 * np.pi * df.index.hour/24) \n",
    "df['hour_sin365_2'] = np.sin(4 * np.pi * df.index.hour/24)\n",
    "df['hour_cos365_2'] = np.cos(4 * np.pi * df.index.hour/24) \n",
    "\n",
    "# Shift predicted weather values by 24hr\n",
    "df['pred_24h_diffuse_solar_W_m2_shift'] = df['pred_24h_diffuse_solar_W_m2'].shift(periods=24)\n",
    "df['pred_24h_direct_solar_W_m2_shift'] = df['pred_24h_direct_solar_W_m2'].shift(periods=24)\n",
    "df['pred_24h_outdoor_temp_shift'] = df['pred_24h_outdoor_temp'].shift(periods=24)\n",
    "df['pred_24h_outdoor_hum_shift'] = df['pred_24h_outdoor_hum'].shift(periods=24)\n",
    "df = df.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec687dd807b97788016aa2a8dc46410b9e66b8caf0629350de408a3d76b46c87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
