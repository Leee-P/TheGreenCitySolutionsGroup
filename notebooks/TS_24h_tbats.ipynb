{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly prediction\n",
    "- goal is the most accurate prediction of net load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from tbats import TBATS\n",
    "from green_city.utils import metrics_dict, datetime2index, index2datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [25, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLFLOW ##\n",
    "import mlflow\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "\n",
    "flow_conf = get_mlflow_config()\n",
    "tracking_uri = flow_conf[\"TRACKING_URI\"]\n",
    "mlflow.set_tracking_uri(flow_conf[\"TRACKING_URI\"])\n",
    "mlflow.set_experiment(flow_conf[\"EXPERIMENT_NAME\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document wide parameters that don't change in experiments\n",
    "#for logging to mlflow server\n",
    "global_params = {\n",
    "    \"feature\": \"net_load_kWh\",\n",
    "    \"building_nr\": 5,\n",
    "    \"resolution\": \"H\",\n",
    "    \"pred_steps\": 24,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert global_params[\"resolution\"] == \"H\"\n",
    "\n",
    "# Load the dataset\n",
    "def get_df(building_nr, feature):\n",
    "    df = (\n",
    "    pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\")\n",
    "        .astype({'datetime': 'datetime64'})\n",
    "        [[feature, \"datetime\"]]\n",
    "        .rename(columns={feature: \"actual\"})\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = get_df(global_params[\"building_nr\"], global_params[\"feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = False\n",
    "if plotting:\n",
    "    #Plotting the data to get a bit of an overview\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    df.actual.plot(ax=ax1, xlabel=\"\");\n",
    "    #ax1.set_xlabel(\"\")\n",
    "    plot_acf(df.actual, lags=370, ax=ax2);\n",
    "    plt.subplots_adjust(hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def predict_next_hours(index=None,\n",
    "                       time=None,\n",
    "                       data=None,\n",
    "                       pred_steps=24,\n",
    "                       train_steps=None,\n",
    "                       model='TBATS',\n",
    "                       seasonalities=None,\n",
    "                       **_):\n",
    "    df = data\n",
    "    if index is None:\n",
    "        index = df.loc[df.datetime == time].index[0]\n",
    "    if seasonalities is None:\n",
    "        seasonalities = [24]\n",
    "        if train_steps > 7*24:\n",
    "            seasonalities.append(7*24)\n",
    "        if train_steps > 365*24:\n",
    "            seasonalities.append(365*24)\n",
    "\n",
    "    print(f\"[Predicting the next {pred_steps}h after {df.loc[index, 'datetime']} (row {index})]\")\n",
    "\n",
    "    if train_steps is not None:\n",
    "        df_train = df.loc[index-train_steps+1:index]\n",
    "    else:\n",
    "        df_train = df.loc[:index]\n",
    "\n",
    "    if model == 'TBATS':\n",
    "        #estimator = TBATS(seasonal_periods=[24, 7*24, 365*24])\n",
    "        estimator = TBATS(seasonal_periods=[24])\n",
    "        fitted_model = estimator.fit(df_train.actual)\n",
    "        forecast = fitted_model.forecast(steps=pred_steps)\n",
    "\n",
    "    return pd.DataFrame({\"forecast\": forecast}, index=range(index+1, index+pred_steps+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we could also define multiple parameter dictionaries at one place and let them run:\n",
    "\n",
    "for timestr in [\"2008-10-03 14:00\", \"2009-06-06 19:00\", \"2008-04-02 01:00\"]:\n",
    "    for train_steps in [100, 200, 400 ,1000]:\n",
    "        params = global_params.copy()\n",
    "        params.update({\n",
    "            \"index\": datetime2index(timestr),\n",
    "            \"datetime\": pd.Timestamp(timestr),\n",
    "            pred_steps: 24,\n",
    "            \"train_steps\": time_steps,\n",
    "            \"model\": \"TBATS\",\n",
    "            \"seasonalities\": [24],\n",
    "        })\n",
    "\n",
    "        with mlflow.start_run(run_name=\"test_TBATS\") as r:\n",
    "\n",
    "            ## predict ##\n",
    "            predictions = predict_next_hours(**params, data=df)\n",
    "            df_forecast = pd.concat([df, predictions], axis=1)\n",
    "            df_forecast[\"error\"] = df_forecast.actual - df_forecast.forecast\n",
    "\n",
    "            ## evaluate ##\n",
    "            pred_lims = (params[\"index\"]+1, params[\"index\"]+params[\"pred_steps\"])\n",
    "            df_predrange = df_forecast.loc[pred_lims[0]:pred_lims[1]]\n",
    "\n",
    "            metrics = metrics_dict(df_predrange.actual, df_predrange.forecast, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## logging ##\n",
    "            mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 64\n",
    "\n",
    "params = global_params.copy()\n",
    "params.update({\n",
    "    \"index\": index,\n",
    "    \"datetime\": index2datetime(index),\n",
    "    \"pred_steps\": 24,\n",
    "    \"train_steps\": 200,\n",
    "    \"model\": \"TBATS\",\n",
    "    \"seasonalities\": [24],\n",
    "})\n",
    "\n",
    "with mlflow.start_run(run_name=\"24h_TBATS\") as r:\n",
    "\n",
    "    ## predict ##\n",
    "    predictions = predict_next_hours(**params, data=df)\n",
    "    df_forecast = pd.concat([df, predictions], axis=1)\n",
    "    df_forecast[\"error\"] = df_forecast.actual - df_forecast.forecast\n",
    "\n",
    "    ## evaluate ##\n",
    "    pred_lims = (params[\"index\"]+1, params[\"index\"]+params[\"pred_steps\"])\n",
    "    df_predrange = df_forecast.loc[pred_lims[0]:pred_lims[1]]\n",
    "\n",
    "    metrics = metrics_dict(df_predrange.actual, df_predrange.forecast, [\"mae\", \"mse\", \"r2_score\"])\n",
    "    print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    ## logging ##\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "df_forecast.loc[:params[\"index\"]+params[\"pred_steps\"]+10].set_index(\"datetime\").plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = \"2009-01-03 22:00\"\n",
    "\n",
    "index_dt = pd.Timestamp.fromisoformat(start_time)\n",
    "#second forecast:\n",
    "params = global_params.copy()\n",
    "params.update({\n",
    "    \"datetime\": index_dt,\n",
    "    \"index\": datetime2index(index_dt),\n",
    "    \"pred_steps\": 24,\n",
    "    \"train_steps\": 40,\n",
    "    \"model\": \"TBATS\"\n",
    "})\n",
    "\n",
    "pred_lims = (params[\"index\"]+1, params[\"index\"]+params[\"pred_steps\"])\n",
    "train_lims = (params[\"index\"]-params[\"train_steps\"]+1, params[\"index\"])\n",
    "\n",
    "with mlflow.start_run(run_name=\"predict_2009\") as r:\n",
    "    forecast_2009 = predict_next_hours(**params, data=df)\n",
    "    df_w_fc = pd.concat([df, forecast_2009.rename(columns={\"forecast\": \"fc_2009\"})], axis=1)\n",
    "    df_predrange = df_w_fc.loc[pred_lims[0]:pred_lims[1]]\n",
    "\n",
    "    #calculate error\n",
    "    df_w_fc[\"error\"] = df_w_fc.actual - df_w_fc.fc_2009\n",
    "\n",
    "    metrics = metrics_dict(df_predrange.actual, df_predrange.fc_2009, [\"mae\", \"mse\", \"r2_score\"])\n",
    "    print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "df_w_fc.loc[train_lims[0]:pred_lims[1]+10].set_index('datetime').plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adec6c5f7a7e6b374924807d676c9e580fd19dbf1c8cad640c4c5a1bb48bcada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
