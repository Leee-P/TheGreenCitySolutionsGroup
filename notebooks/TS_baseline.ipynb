{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from tbats import TBATS\n",
    "from green_city.utils import metrics_dict, datetime2index, index2datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [25, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLFLOW ##\n",
    "import mlflow\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "\n",
    "flow_conf = get_mlflow_config()\n",
    "tracking_uri = flow_conf[\"TRACKING_URI\"]\n",
    "mlflow.set_tracking_uri(flow_conf[\"TRACKING_URI\"])\n",
    "mlflow.set_experiment(flow_conf[\"EXPERIMENT_NAME\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    \"feature\": \"net_load_kW\",\n",
    "    #\"building_nr\": 5,\n",
    "    \"building_nr\": \"all\",\n",
    "    \"resolution\": \"H\",\n",
    "    \"pred_steps\": 24,\n",
    "    \"model\": \"baseline_Y\"\n",
    "}\n",
    "\n",
    "assert global_params[\"resolution\"] == \"H\"\n",
    "\n",
    "# Load the dataset\n",
    "def get_df(building_nr, feature):\n",
    "    if building_nr == \"all\":\n",
    "        filename = \"Agg_buildings.csv\"\n",
    "    else:\n",
    "        filename = f\"Building_{building_nr}.csv\"\n",
    "    df = (\n",
    "    pd.read_csv(Path(\"../data/preprocessed\") / filename)\n",
    "        .astype({'datetime': 'datetime64'})\n",
    "        [[feature, \"datetime\"]]\n",
    "        .rename(columns={feature: \"actual\"})\n",
    "    )\n",
    "    df.index.name = \"id\"\n",
    "    return df\n",
    "\n",
    "df = get_df(global_params[\"building_nr\"], global_params[\"feature\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "for index in indices:\n",
    "    pred_from, pred_to = (index+1, index+24)\n",
    "\n",
    "    df[\"baseline_Y\"] = df[\"actual\"].shift(365*24) #usage data from one year ago\n",
    "    df[\"baseline_W\"] = df[\"actual\"].shift(7*24)     #usage data from the previous 24 hours\n",
    "    #df.loc[pred_lims[0]:pred_lims[1]].set_index(\"datetime\").plot()\n",
    "\n",
    "    #for shift in [\"Y\", \"W\"]:\n",
    "    for shift in [\"Y\"]:\n",
    "        with mlflow.start_run(run_name=f\"baseline_{shift}_{index}\") as r:\n",
    "            scores = metrics_dict(\n",
    "                df.loc[pred_from:pred_to, \"actual\"],\n",
    "                df.loc[pred_from:pred_to, f\"baseline_{shift}\"],\n",
    "                [\"mae\", \"mse\", \"r2_score\"]\n",
    "            )\n",
    "            params = global_params.copy()\n",
    "            params.update({\n",
    "                \"index\": index,\n",
    "                \"datetime\": index2datetime(index),\n",
    "                #\"model\": f\"baseline_{shift}\"\n",
    "                \"model\": \"baseline\"\n",
    "            })\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(scores)\n",
    "\n",
    "            forecasts = df.loc[pred_from:pred_to, [f\"baseline_{shift}\"]].assign(run_id = r.info.run_id).rename(columns={f\"baseline_{shift}\": \"prediction\"})\n",
    "            forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adec6c5f7a7e6b374924807d676c9e580fd19dbf1c8cad640c4c5a1bb48bcada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
