{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS Prophet\n",
    "## Data split in training and test. The last 365 days are the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import cross\n",
    "import itertools\n",
    "from matplotlib import units\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "from green_city.utils import metrics_dict, datetime2index, index2datetime\n",
    "\n",
    "# Libraries to reduce Prophet verbose output\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLFLOW ##\n",
    "import mlflow\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "\n",
    "flow_conf = get_mlflow_config()\n",
    "tracking_uri = flow_conf[\"TRACKING_URI\"]\n",
    "mlflow.set_tracking_uri(flow_conf[\"TRACKING_URI\"])\n",
    "mlflow.set_experiment(flow_conf[\"EXPERIMENT_NAME\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_winter_season(ds):\n",
    "    \"\"\"Classifies the dates into Winter or Summer\n",
    "\n",
    "    Args:\n",
    "        ds (datetime series): A Pandas datetime series\n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(ds)\n",
    "    return(date.month < 4 or date.month > 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "building = 5\n",
    "# Load data\n",
    "df_building = pd.read_csv(f\"../data/preprocessed/Building_{building}.csv\").astype({'datetime': 'datetime64'})#.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building = df_building.rename(columns={'datetime':'ds',\n",
    "                                    'net_load_kW':'y'})\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building['winter'] = df_building['ds'].apply(is_winter_season)\n",
    "df_building['summer'] = ~df_building['ds'].apply(is_winter_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holiday = df_building[['ds','holiday']].query('holiday')\n",
    "df_holiday['holiday'] = 'Holiday'\n",
    "# df_holiday\n",
    "\n",
    "## In the development stage, it was explored to add the workday as part of the  ##\n",
    "## seasonality. It did not had an effect. Including the holiday did.            ##\n",
    "# df_workday = df[['ds','workday']].query('workday')\n",
    "# df_workday['holiday'] = 'Workday'\n",
    "# df_workday = df_workday.drop('workday', axis=1)\n",
    "\n",
    "# df_holidays = pd.concat([df_holiday, df_workday], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "# pred_indices = [32135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet simple model. Three years training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_model_train = df_building[:365*3*24]\n",
    "df_simple_model_test = df_building[365*3*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prophed model. Specify 95% of uncertainty and additive model. (Default 80% and additive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_simple = Prophet(interval_width = 0.95, seasonality_mode=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -611.572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x15f451ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       46462.1     0.0216691       1348.58      0.8278      0.8278      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       46484.9    0.00404769       214.728           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       46495.5     0.0035042       622.477      0.9031      0.9031      356   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399         46508    0.00111895       109.971      0.7704      0.7704      479   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       46511.4    0.00205959       410.796           1           1      594   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       46515.1    0.00226633       244.605           1           1      710   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     653         46516   5.06798e-05        184.73    2.63e-07       0.001      814  LS failed, Hessian reset \n",
      "     699       46516.1   1.65527e-05       87.4175      0.8162      0.8162      872   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     729       46517.9   0.000198855       739.808   2.075e-07       0.001      948  LS failed, Hessian reset \n",
      "     777         46519   0.000131413       180.899   8.695e-07       0.001     1050  LS failed, Hessian reset \n",
      "     799       46519.1    0.00101929       87.0526       2.548      0.2548     1078   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     849       46519.5   0.000117087       215.967    1.51e-06       0.001     1187  LS failed, Hessian reset \n",
      "     899       46519.6   1.60337e-06       73.8607      0.7549      0.7549     1256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     901       46519.6   3.29147e-06       68.3803           1           1     1259   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "my_model_simple.fit(df_simple_model_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting 8 days with basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params)\n",
    "            my_model.fit(df_train) \n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "            \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MSE for tunning \n",
    "param_grid_simple = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.05],\n",
    "    'seasonality_prior_scale':[10.0],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.8]\n",
    "}\n",
    "my_simple_params = [dict(zip(param_grid_simple.keys(), v)) for v in itertools.product(*param_grid_simple.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -566.469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       56662.2     0.0146764        1653.5      0.9621      0.9621      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       56678.9    0.00372142       570.846           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       56684.3    0.00259097        555.83           1           1      359   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     380       56686.1   2.97352e-05       143.893   2.735e-07       0.001      511  LS failed, Hessian reset \n",
      "     399       56686.7   0.000423781       228.997      0.6589      0.6589      534   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     493         56688   2.03662e-05       94.3369   2.754e-07       0.001      695  LS failed, Hessian reset \n",
      "     499         56688    0.00115153        142.49           1           1      703   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     560       56688.8   0.000228231       427.201    8.37e-07       0.001      810  LS failed, Hessian reset \n",
      "     599       56689.5   0.000295499       172.351           1           1      855   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699         56690   1.57571e-05       69.2915       0.758       0.758      983   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     724       56691.3    2.4165e-05       112.025   1.418e-07       0.001     1061  LS failed, Hessian reset \n",
      "     751       56692.1   5.78826e-05       144.283   6.964e-07       0.001     1135  LS failed, Hessian reset \n",
      "     799       56692.3   0.000229713       183.522           1           1     1189   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       56692.4   4.84566e-05       65.4148      0.5498      0.5498     1324   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     913       56692.4   1.69221e-05       83.0529   2.464e-07       0.001     1389  LS failed, Hessian reset \n",
      "     932       56692.4   2.26796e-06       62.4647      0.3804      0.3804     1417   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "32135\n",
      "mae: 4.269149156256524, mse: 25.215746926283174, r2: 0.6677353547949973\n",
      "Initial log joint probability = -624.243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       58499.8    0.00361928        484.11      0.9223      0.9223      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       58528.6   0.000489447       184.075           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299         58535    0.00317713       177.303           1           1      358   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     363       58537.5   0.000149815       430.213   5.157e-07       0.001      473  LS failed, Hessian reset \n",
      "     399       58539.6    0.00216448       259.277           1           1      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       58541.7   4.07567e-05       79.4267     0.03951      0.8772      641   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     515       58541.9    0.00013771       212.113   2.596e-06       0.001      703  LS failed, Hessian reset \n",
      "     532         58542   1.48092e-05       75.5764   1.643e-07       0.001      768  LS failed, Hessian reset \n",
      "     599       58543.1    0.00225598       439.797           1           1      859   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699         58545    0.00209721       208.492      0.2378           1      977   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     746       58545.2   1.71651e-05       86.2609   1.597e-07       0.001     1085  LS failed, Hessian reset \n",
      "     756       58545.2   9.89838e-06         37.93   1.148e-07       0.001     1145  LS failed, Hessian reset \n",
      "     782       58545.3   1.16176e-05       78.5467   1.833e-07       0.001     1236  LS failed, Hessian reset \n",
      "     798       58545.3   2.46299e-06       54.0211     0.04281           1     1256   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "33311\n",
      "mae: 7.734472339572952, mse: 77.01257912946112, r2: -0.97869711704765\n",
      "Initial log joint probability = -675.252\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       46772.4    0.00614652       954.505      0.7264      0.7264      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       46806.8    0.00194851       460.369           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299         46813   0.000522098       297.957      0.2931      0.2931      355   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       46817.9    0.00406915        811.72           1           1      466   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       46824.9   0.000369381       333.809           1           1      591   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     564       46826.2   3.42538e-05       94.2253    1.35e-07       0.001      708  LS failed, Hessian reset \n",
      "     599       46826.7   7.56305e-05       73.2632      0.3547      0.3547      750   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       46829.3   0.000418168       147.765           1           1      865   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     750       46829.7   4.08681e-05       126.593   1.416e-07       0.001      974  LS failed, Hessian reset \n",
      "     799       46829.9   0.000621959        111.65           1           1     1034   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     840       46830.4   5.09627e-05       176.167   1.512e-07       0.001     1132  LS failed, Hessian reset \n",
      "     899       46830.9    0.00113849       176.945           1           1     1209   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     978       46831.6   5.98122e-05           215   2.629e-07       0.001     1348  LS failed, Hessian reset \n",
      "     999         46832   0.000320535       197.471           1           1     1371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1060       46832.2   0.000194499        208.47   1.784e-06       0.001     1483  LS failed, Hessian reset \n",
      "    1099       46832.2   3.72178e-05       86.8895      0.6822      0.6822     1530   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1133       46832.3   6.63609e-05       167.153   8.259e-07       0.001     1621  LS failed, Hessian reset \n",
      "    1179       46832.3   3.35219e-06       65.8999      0.7441      0.7441     1679   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "26478\n",
      "mae: 5.195662157028797, mse: 53.92661893333, r2: -0.24124450255857188\n",
      "Initial log joint probability = -682.632\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       58569.1    0.00415505       411.377      0.9834      0.9834      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       58602.9     0.0190566       1229.65           1           1      230   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       58612.3   0.000467115       115.212           1           1      344   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     384       58616.2   2.34221e-05       98.8218   1.213e-07       0.001      498  LS failed, Hessian reset \n",
      "     399       58616.4   0.000774488        236.25           1           1      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       58616.9   0.000222908       78.6717      0.5182      0.5182      628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     563       58618.1   2.92062e-05       116.109   1.217e-07       0.001      748  LS failed, Hessian reset \n",
      "     599       58618.7   0.000995234       134.442           1           1      798   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     639       58618.8   1.02657e-05       43.6935   2.848e-07       0.001      899  LS failed, Hessian reset \n",
      "     695       58619.1   5.71874e-05       121.876   6.694e-07       0.001     1018  LS failed, Hessian reset \n",
      "     699       58619.1   0.000121846       168.784           1           1     1022   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     768       58619.3   1.11478e-05       58.6683   2.395e-07       0.001     1153  LS failed, Hessian reset \n",
      "     770       58619.3   4.79843e-06        39.314           1           1     1155   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "33357\n",
      "mae: 6.067488733395265, mse: 63.24580271006622, r2: 0.14516744747240573\n",
      "Initial log joint probability = -707.702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       53428.5    0.00489415       682.205           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       53444.6    0.00298388       363.336           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       53449.6    0.00144305       155.112        0.18           1      355   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     336       53453.1   4.46483e-05       172.505   1.412e-07       0.001      442  LS failed, Hessian reset \n",
      "     399       53455.2   0.000363489       301.088           1           1      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     472       53458.2   5.15422e-05       200.156   2.546e-07       0.001      645  LS failed, Hessian reset \n",
      "     499       53458.8    0.00104554       377.937           1           1      677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599         53461    0.00412816       291.566           1           1      792   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       53463.8    0.00299116       199.429           1           1      930   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       53464.8   0.000229401       88.4168           1           1     1059   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     889       53465.9   0.000182746       206.009     7.8e-07       0.001     1212  LS failed, Hessian reset \n",
      "     899       53466.3   0.000410801       110.257           1           1     1224   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       53466.9   0.000612956       126.854           1           1     1343   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       53467.2    0.00165339       103.754           1           1     1475   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       53467.9   0.000520333       71.5865           1           1     1599   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       53468.2    0.00155704       152.471           1           1     1729   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1315       53468.3   1.91771e-05       80.5229   1.433e-07       0.001     1784  LS failed, Hessian reset \n",
      "    1345       53468.3   1.84816e-05       71.6776    1.26e-07       0.001     1862  LS failed, Hessian reset \n",
      "    1368       53468.3   3.19262e-06       56.0132           1           1     1897   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "30387\n",
      "mae: 4.741399810448423, mse: 42.79272366270512, r2: 0.49126656489602594\n",
      "Initial log joint probability = -579.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       54177.3     0.0177326       1067.19           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       54195.6    0.00379848       469.656           1           1      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     297       54206.5   0.000107706        238.75    7.01e-07       0.001      395  LS failed, Hessian reset \n",
      "     299       54206.5   0.000142701       162.693       9.415      0.9415      398   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       54208.8   7.48619e-05       190.479      0.5729      0.5729      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       54211.5   0.000768072       333.532      0.3655      0.3655      635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     501       54211.5   2.38794e-05       74.1113   1.166e-07       0.001      681  LS failed, Hessian reset \n",
      "     599       54212.9    0.00196096       355.801           1           1      802   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     654       54213.2   4.55087e-05       164.554   4.726e-07       0.001      905  LS failed, Hessian reset \n",
      "     699       54213.3    0.00196328       83.1618           1           1      959   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     777       54213.6   2.36281e-05       112.649    1.72e-07       0.001     1103  LS failed, Hessian reset \n",
      "     799       54213.7   3.88133e-05       53.1924      0.5848      0.5848     1132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     894       54214.8   0.000163232       116.767   1.712e-06       0.001     1293  LS failed, Hessian reset \n",
      "     899       54214.9   0.000778609       133.545       0.698       0.698     1300   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       54215.2   5.81372e-05       60.0148      0.3565           1     1431   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1048       54215.5   6.92379e-05       176.832   7.293e-07       0.001     1538  LS failed, Hessian reset \n",
      "    1099       54215.8   0.000293702       72.8998      0.5401           1     1597   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       54215.9   3.36996e-05       132.323   3.032e-07       0.001     1690  LS failed, Hessian reset \n",
      "    1165       54215.9    1.6559e-05        77.843    2.45e-07       0.001     1759  LS failed, Hessian reset \n",
      "    1168       54215.9   3.91127e-06       48.3518      0.6158           1     1764   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "30794\n",
      "mae: 4.185443767645464, mse: 26.23707681405575, r2: 0.5670932729428156\n",
      "Initial log joint probability = -523.331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       56054.8    0.00163594       276.771      0.9819      0.9819      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       56077.7      0.010684       506.673           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       56081.9    0.00601561       337.575       0.664       0.664      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       56084.7    0.00029961        97.635      0.3608           1      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       56086.8   0.000756158       108.501      0.2942           1      621   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       56088.8    0.00232177       93.3871           1           1      744   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       56089.5   0.000708973       145.747           1           1      868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       56089.9   8.23888e-05       79.3632      0.3534           1      990   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     841       56090.3   5.83919e-05        223.12   3.357e-07       0.001     1086  LS failed, Hessian reset \n",
      "     899       56090.9   4.38742e-05       74.0275           1           1     1167   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     934         56091   0.000539159       134.827   7.588e-06       0.001     1261  LS failed, Hessian reset \n",
      "     968         56091   3.24588e-06       73.5224      0.3882      0.3882     1308   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "31800\n",
      "mae: 6.167936074679193, mse: 55.98942005629507, r2: 0.1840696736962638\n",
      "Initial log joint probability = -508.368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       50694.6     0.0121536       1965.72           1           1      115   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       50725.8      0.012869       363.525      0.9668      0.9668      227   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299         50733    0.00108239       178.289           1           1      336   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       50740.9    0.00332908       398.269           1           1      445   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       50746.5   0.000916999       343.969       0.341       0.341      562   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       50748.2     0.0027386       300.132           1           1      680   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     674       50752.1   4.36525e-05       181.821   2.277e-07       0.001      812  LS failed, Hessian reset \n",
      "     699       50752.5   6.90589e-05       80.9477      0.9588      0.9588      841   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       50753.7   0.000264499       212.519      0.6406      0.6406      959   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     833       50753.9   3.38776e-05       124.343   1.387e-07       0.001     1043  LS failed, Hessian reset \n",
      "     899       50754.1   0.000366318       70.1331      0.6426      0.6426     1120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       50755.8    0.00389079       559.355      0.2402           1     1236   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1051       50755.9   4.15661e-05       165.129   4.064e-07       0.001     1354  LS failed, Hessian reset \n",
      "    1071         50756    1.1904e-06       73.8138       0.287           1     1379   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "28783\n",
      "mae: 3.87914385043431, mse: 23.644765136157243, r2: 0.535269842646898\n"
     ]
    }
   ],
   "source": [
    "pred_mse_simpleMod, \\\n",
    "    my_model_simpleMod, \\\n",
    "    ls_publish_mse_simpleMod = my_pred(df = df_building,\n",
    "        model_name='Prophet Simple Model', \n",
    "        params=my_simple_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize modeling. Find best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prophet_find_hyperparameter(df, all_params):\n",
    "    \"\"\"Determine the best hyper parameters for a Prophet model.\n",
    "    It uses a base Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe): A pandas dataframe with the required Prophet structure\n",
    "        all_params (list of dictionaries): A list of dictionaries with the parameters definition. \n",
    "\n",
    "    Returns:\n",
    "        best_params: a list with the best parameters\n",
    "        tuning_results: A dataframe with the mse and rmse evaluation of the parameters combinations\n",
    "    \"\"\"\n",
    "    warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    logging.getLogger('prophet').setLevel(logging.ERROR) #Notice that i had modified the name from 'fbprophet' to just 'prophet'\n",
    "    mses = []\n",
    "    rmses = []\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params)\n",
    "        m.fit(df)\n",
    "        df_cv = cross_validation(m, horizon='180 days', parallel='processes')\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        mses.append(df_p['mse'].values[0])\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['mse'] = mses\n",
    "    tuning_results['rmse'] = rmses\n",
    "    print(tuning_results)\n",
    "    best_params=all_params[np.argmin(mses)]\n",
    "    print(best_params)\n",
    "    return best_params, tuning_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter optimization. Tunning CV with MSE \n",
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001, 0.01, 0.05, 0.1, 0.5], #Parameters like this (regularization penalties; this is effectively a lasso penalty) are often tuned on a log scale.\n",
    "    'seasonality_prior_scale':[0.01, 0.1, 1.0, 10.0], #This likely also makes sense on a log scale, since it is effectively an L2 penalty like in ridge regression.\n",
    "    'holidays_prior_scale':[0.01, 0.1, 1.0, 10.0],\n",
    "    'changepoint_range':[0.8,0.9]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not run. It takes 95m. The results are in the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_optimized_parameters, \\\n",
    "#     my_optimized_param_tunning_results = \\\n",
    "#         my_prophet_find_hyperparameter(df_simple_model_train, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_optimized_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimized_parameters = {'interval_width': 0.95,\n",
    "    'seasonality_mode': 'additive',\n",
    "    'changepoint_prior_scale': 0.0001,\n",
    "    'seasonality_prior_scale': 0.01,\n",
    "    'holidays_prior_scale': 0.01,\n",
    "    'changepoint_range': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the hyperparameters results from cross validation. RMSE and MSE are documented.\n",
    "# my_optimized_param_tunning_results\n",
    "# my_optimized_param_tunning_results.to_csv('../data/preprocessed/prophet_best_hyperparameters.csv',\n",
    "#     sep=\";\", index_label='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters that can be tuned\n",
    "\n",
    "**changepoint_prior_scale**: This is probably the most impactful parameter. It determines the flexibility of the trend, and in particular how much the trend changes at the trend changepoints. As described in this documentation, if it is too small, the trend will be underfit and variance that should have been modeled with trend changes will instead end up being handled with the noise term. If it is too large, the trend will overfit and in the most extreme case you can end up with the trend capturing yearly seasonality. The default of 0.05 works for many time series, but this could be tuned; a range of [0.001, 0.5] would likely be about right. Parameters like this (regularization penalties; this is effectively a lasso penalty) are often tuned on a log scale.\n",
    "\n",
    "**seasonality_prior_scale**: This parameter controls the flexibility of the seasonality. Similarly, a large value allows the seasonality to fit large fluctuations, a small value shrinks the magnitude of the seasonality. The default is 10., which applies basically no regularization. That is because we very rarely see overfitting here (there’s inherent regularization with the fact that it is being modeled with a truncated Fourier series, so it’s essentially low-pass filtered). A reasonable range for tuning it would probably be [0.01, 10]; when set to 0.01 you should find that the magnitude of seasonality is forced to be very small. This likely also makes sense on a log scale, since it is effectively an L2 penalty like in ridge regression.\n",
    "\n",
    "**holidays_prior_scale**: This controls flexibility to fit holiday effects. Similar to seasonality_prior_scale, it defaults to 10.0 which applies basically no regularization, since we usually have multiple observations of holidays and can do a good job of estimating their effects. This could also be tuned on a range of [0.01, 10] as with seasonality_prior_scale.\n",
    "\n",
    "**seasonality_mode**: Options are ['additive', 'multiplicative']. Default is 'additive', but many business time series will have multiplicative seasonality. This is best identified just from looking at the time series and seeing if the magnitude of seasonal fluctuations grows with the magnitude of the time series (see the documentation here on multiplicative seasonality), but when that isn’t possible, it could be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -566.469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       55998.8   1.90867e-06       50957.3      0.4055      0.4055      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       55999.4   2.77281e-06       50843.4   5.876e-11       0.001      198  LS failed, Hessian reset \n",
      "     139       55999.5   8.61943e-09       45383.6      0.2944      0.2944      225   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "32135\n",
      "mae: 5.133991341371004, mse: 39.884219908762326, r2: 0.47445077807906966\n",
      "Initial log joint probability = -624.243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      60       57769.6   0.000948796       41754.6   2.083e-08       0.001      118  LS failed, Hessian reset \n",
      "      99       57836.2   5.68014e-07       56942.8      0.6864      0.6864      165   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       57836.3   8.96866e-07       43748.7   1.909e-11       0.001      227  LS failed, Hessian reset \n",
      "     135       57836.3   2.84703e-09       38354.5      0.2148      0.2148      248   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33311\n",
      "mae: 5.424390136141459, mse: 44.47272458170696, r2: -0.14264517448700964\n",
      "Initial log joint probability = -675.252\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      60       46376.2   0.000108807       48514.5   2.098e-09       0.001      135  LS failed, Hessian reset \n",
      "      99       46389.3   1.27394e-05       47191.3           1           1      184   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     163       46394.6   7.09527e-09       42843.2      0.3455      0.3455      265   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "26478\n",
      "mae: 5.784939662289808, mse: 61.93068026450513, r2: -0.42547628496913803\n",
      "Initial log joint probability = -682.632\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      80       57888.1   0.000153764       44426.9   3.485e-09       0.001      159  LS failed, Hessian reset \n",
      "      99       57899.5   4.46265e-06       48994.4       0.409       0.409      181   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     142       57900.4   8.98157e-09       42235.9      0.3314      0.3314      234   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33357\n",
      "mae: 8.239491268098007, mse: 96.84851642700238, r2: -0.3090080441437473\n",
      "Initial log joint probability = -707.702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       52903.3   3.53238e-08       46513.5      0.3234      0.3234      138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     113       52903.3   4.90058e-09       45718.1      0.5412      0.5412      154   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30387\n",
      "mae: 4.866231135443621, mse: 33.737090038764585, r2: 0.5989228018970221\n",
      "Initial log joint probability = -579.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      70       53541.3   0.000200286       47466.2   4.227e-09       0.001      129  LS failed, Hessian reset \n",
      "      99       53548.1   2.52547e-07       43202.1      0.2805      0.2805      164   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     149       53549.9   9.93509e-06       44426.8   1.914e-10       0.001      268  LS failed, Hessian reset \n",
      "     190       53550.3   4.31168e-07       43888.1   9.283e-12       0.001      362  LS failed, Hessian reset \n",
      "     199       53550.3   8.34331e-08       38112.5       0.359           1      372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     202       53550.3   8.62244e-09       42734.5      0.1745      0.1745      376   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30794\n",
      "mae: 5.61380382453422, mse: 44.47478258192871, r2: 0.2661746313976501\n",
      "Initial log joint probability = -523.331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       55235.7   1.36045e-07       43362.7      0.9804      0.9804      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     104       55235.7    6.4688e-09       45630.5      0.1879      0.1879      142   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "31800\n",
      "mae: 4.759155845030532, mse: 35.62783516932785, r2: 0.48079778025961184\n",
      "Initial log joint probability = -508.368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      90       50386.3    3.2698e-09       49734.9       0.112       0.112      122   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "28783\n",
      "mae: 3.793108236145947, mse: 21.497871749271244, r2: 0.5774663328959027\n"
     ]
    }
   ],
   "source": [
    "pred_simpleMod_Opt, \\\n",
    "        my_model_simpleMod_Opt, \\\n",
    "        ls_publish_simpleMod_Opt = my_pred(df = df_building,\n",
    "        model_name='Prophet Simple Model Optimized Parameters - Tunning with MSE', \n",
    "        params=my_optimized_parameters,\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -566.469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       55998.8   1.90867e-06       50957.3      0.4055      0.4055      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       55999.4   2.77281e-06       50843.4   5.876e-11       0.001      198  LS failed, Hessian reset \n",
      "     139       55999.5   8.61943e-09       45383.6      0.2944      0.2944      225   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "32135\n",
      "mae: 5.133991341371004, mse: 39.884219908762326, r2: 0.47445077807906966\n",
      "Initial log joint probability = -624.243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      60       57769.6   0.000948796       41754.6   2.083e-08       0.001      118  LS failed, Hessian reset \n",
      "      99       57836.2   5.68014e-07       56942.8      0.6864      0.6864      165   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       57836.3   8.96866e-07       43748.7   1.909e-11       0.001      227  LS failed, Hessian reset \n",
      "     135       57836.3   2.84703e-09       38354.5      0.2148      0.2148      248   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33311\n",
      "mae: 5.424390136141459, mse: 44.47272458170696, r2: -0.14264517448700964\n",
      "Initial log joint probability = -675.252\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      60       46376.2   0.000108807       48514.5   2.098e-09       0.001      135  LS failed, Hessian reset \n",
      "      99       46389.3   1.27394e-05       47191.3           1           1      184   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     163       46394.6   7.09527e-09       42843.2      0.3455      0.3455      265   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "26478\n",
      "mae: 5.784939662289808, mse: 61.93068026450513, r2: -0.42547628496913803\n",
      "Initial log joint probability = -682.632\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      80       57888.1   0.000153764       44426.9   3.485e-09       0.001      159  LS failed, Hessian reset \n",
      "      99       57899.5   4.46265e-06       48994.4       0.409       0.409      181   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     142       57900.4   8.98157e-09       42235.9      0.3314      0.3314      234   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33357\n",
      "mae: 8.239491268098007, mse: 96.84851642700238, r2: -0.3090080441437473\n",
      "Initial log joint probability = -707.702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       52903.3   3.53238e-08       46513.5      0.3234      0.3234      138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     113       52903.3   4.90058e-09       45718.1      0.5412      0.5412      154   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30387\n",
      "mae: 4.866231135443621, mse: 33.737090038764585, r2: 0.5989228018970221\n",
      "Initial log joint probability = -579.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      70       53541.3   0.000200286       47466.2   4.227e-09       0.001      129  LS failed, Hessian reset \n",
      "      99       53548.1   2.52547e-07       43202.1      0.2805      0.2805      164   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     149       53549.9   9.93509e-06       44426.8   1.914e-10       0.001      268  LS failed, Hessian reset \n",
      "     190       53550.3   4.31168e-07       43888.1   9.283e-12       0.001      362  LS failed, Hessian reset \n",
      "     199       53550.3   8.34331e-08       38112.5       0.359           1      372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     202       53550.3   8.62244e-09       42734.5      0.1745      0.1745      376   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30794\n",
      "mae: 5.61380382453422, mse: 44.47478258192871, r2: 0.2661746313976501\n",
      "Initial log joint probability = -523.331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       55235.7   1.36045e-07       43362.7      0.9804      0.9804      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     104       55235.7    6.4688e-09       45630.5      0.1879      0.1879      142   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "31800\n",
      "mae: 4.759155845030532, mse: 35.62783516932785, r2: 0.48079778025961184\n",
      "Initial log joint probability = -508.368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      90       50386.3    3.2698e-09       49734.9       0.112       0.112      122   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "28783\n",
      "mae: 3.793108236145947, mse: 21.497871749271244, r2: 0.5774663328959027\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_Opt_holidays, \\\n",
    "    m_best_Opt_holidays, \\\n",
    "    ls_publish_Opt_holidays = my_pred(df = df_building,\n",
    "        model_name='Prophet Holidays-Optimized-Parameters - Tunning with MSE', \n",
    "        params=my_optimized_parameters,\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add outdoor temperature, humidity, diffuse and direct solar energy as additional regressor. \n",
    "### The temperature, humidity and solar energy data is in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_reg(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params)\n",
    "            my_model.add_regressor(name='outdoor_temp')\n",
    "            my_model.add_regressor(name='outdoor_hum')\n",
    "            my_model.add_regressor(name='diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='direct_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_temp')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_hum')\n",
    "            my_model.add_regressor(name='pred_24h_diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_direct_solar_W_m2')\n",
    "            my_model.fit(df_train) \n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "            \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -566.469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       60813.1   1.01051e-05       49322.4       0.509           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     133       60813.2    4.1996e-09       50470.6      0.3371      0.3371      166   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "32135\n",
      "mae: 4.380689338216249, mse: 29.757863156096438, r2: 0.6078844750256689\n",
      "Initial log joint probability = -624.243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      76       62988.6    0.00200102       48612.4   3.897e-08       0.001      134  LS failed, Hessian reset \n",
      "      99       63074.8   1.56277e-05       49077.4      0.2255       0.865      168   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     140         63089   1.34961e-05       50362.3   2.672e-10       0.001      269  LS failed, Hessian reset \n",
      "     185       63090.5   8.26882e-06       49638.2   1.632e-10       0.001      383  LS failed, Hessian reset \n",
      "     199       63091.1   7.11438e-07       49288.4       0.334      0.0334      402   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     222       63091.4   1.77938e-06       49940.9   3.566e-11       0.001      468  LS failed, Hessian reset \n",
      "     233       63091.4   8.91755e-09       49718.8      0.2538      0.2538      486   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33311\n",
      "mae: 4.314426518702642, mse: 29.17452403284868, r2: 0.25041405900725866\n",
      "Initial log joint probability = -675.252\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      81       49957.1   2.27268e-05       48664.8   4.478e-10       0.001      149  LS failed, Hessian reset \n",
      "      99       49958.8   8.21748e-06       50461.6           1           1      171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     182       49966.4   3.59737e-09       47406.2      0.1546      0.1546      270   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "26478\n",
      "mae: 6.3446572519181075, mse: 60.488390498007256, r2: -0.39227868647005093\n",
      "Initial log joint probability = -682.632\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      50       63106.8   0.000326955       49895.3    6.35e-09       0.001      109  LS failed, Hessian reset \n",
      "      88       63126.8   8.92386e-07       50177.6   1.758e-11       0.001      193  LS failed, Hessian reset \n",
      "      99       63126.8   8.05368e-08       49056.2           1           1      205   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     115       63126.8   2.02938e-07       51363.9   4.229e-12       0.001      263  LS failed, Hessian reset \n",
      "     125       63126.8   6.07615e-09       50744.4      0.6156      0.6156      274   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33357\n",
      "mae: 3.5624303046137733, mse: 20.497989237072414, r2: 0.7229484375186703\n",
      "Initial log joint probability = -707.702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      89       57392.9   7.02214e-09       48795.6       0.356       0.356      119   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30387\n",
      "mae: 4.203453823661397, mse: 26.112819180554805, r2: 0.6895625455700938\n",
      "Initial log joint probability = -579.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       58221.2   6.35173e-08       46712.6      0.4229      0.4229      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     109       58221.2   8.61218e-09       49730.7       0.527       0.527      136   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30794\n",
      "mae: 4.470766080946944, mse: 30.53502340321893, r2: 0.49617797989521306\n",
      "Initial log joint probability = -523.331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       60193.4    5.3555e-08       46726.1      0.8305      0.8305      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     107       60193.4   2.91853e-07       48683.3   5.471e-12       0.001      189  LS failed, Hessian reset \n",
      "     116       60193.4   3.26567e-09         48954      0.2765      0.2765      201   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "31800\n",
      "mae: 4.1077291160487235, mse: 26.27207807046631, r2: 0.6171386449232801\n",
      "Initial log joint probability = -508.368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       54384.6   7.40282e-07       50152.1      0.5755           1      139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     114       54387.3   2.43016e-05       51416.4   4.905e-10       0.001      210  LS failed, Hessian reset \n",
      "     141       54389.2   8.57238e-06       50187.9   1.662e-10       0.001      282  LS failed, Hessian reset \n",
      "     174       54389.9   1.65484e-06       50190.9   3.298e-11       0.001      362  LS failed, Hessian reset \n",
      "     199       54390.4   6.36044e-05       50444.5      0.6772           1      391   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     200       54390.5   7.68805e-06       50856.1   1.524e-10       0.001      432  LS failed, Hessian reset \n",
      "     220         54391   1.79947e-06       50018.7   3.603e-11       0.001      496  LS failed, Hessian reset \n",
      "     237       54391.1   9.27245e-09       50520.2      0.3465      0.3465      517   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "28783\n",
      "mae: 4.171080901139882, mse: 28.56429918801781, r2: 0.4385780032118345\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_best_WkMod_RegMod_Opt, \\\n",
    "    m_best_RegMod_Opt, \\\n",
    "    ls_publish_best_RegMod_Opt = my_pred_reg(df=df_building,\n",
    "        model_name='Prophet Holidays-Regressors-Optimized-Parameters - Tunning with MSE', \n",
    "        params=all_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop. The following results are dubious at the moment. (01.08.2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume different weekly sesonalities. Summer vs Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_reg_wk(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params, weekly_seasonality=False)\n",
    "            my_model.add_regressor(name='outdoor_temp')\n",
    "            my_model.add_regressor(name='outdoor_hum')\n",
    "            my_model.add_regressor(name='diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='direct_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_temp')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_hum')\n",
    "            my_model.add_regressor(name='pred_24h_diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_direct_solar_W_m2')\n",
    "            my_model.add_seasonality(name='weekly_on_winter', period = 7, fourier_order= 10, condition_name='winter')\n",
    "            my_model.add_seasonality(name='weekly_on_summer', period = 7, fourier_order= 10, condition_name='summer')\n",
    "            my_model.fit(df_train) \n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "            \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -566.469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       62417.5   3.60264e-07       49494.3           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     111       62417.5   6.46263e-09       50319.2      0.1781      0.9064      148   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "32135\n",
      "mae: 3.9397767167410542, mse: 25.987502835647074, r2: 0.6575660267096819\n",
      "Initial log joint probability = -624.243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       64580.4   2.09724e-05       50940.8           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     164         64599   6.38406e-06       51330.6   1.272e-10       0.001      252  LS failed, Hessian reset \n",
      "     199       64599.3   2.88787e-08       52768.5           1           1      301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     204       64599.3   6.16175e-08         48314   1.231e-12       0.001      350  LS failed, Hessian reset \n",
      "     207       64599.3   8.12516e-09         48899      0.3478      0.3478      354   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33311\n",
      "mae: 5.398238200203791, mse: 42.71387039480974, r2: -0.09745463875556348\n",
      "Initial log joint probability = -675.252\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      76       51425.3   1.10931e-06       51321.5   2.226e-11       0.001      152  LS failed, Hessian reset \n",
      "      99       51425.4   1.79893e-07       47683.1      0.1292      0.1292      185   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     117       51425.4    7.6502e-09       50530.3      0.3302      0.8719      210   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "26478\n",
      "mae: 6.407951688949879, mse: 60.25058886981282, r2: -0.38680513797889216\n",
      "Initial log joint probability = -682.632\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       64689.2   6.82153e-08       49635.7      0.4273      0.4273      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       64689.2   6.57107e-09       51943.8      0.3983      0.3983      148   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "33357\n",
      "mae: 3.3528979699665453, mse: 18.36455280438942, r2: 0.7517840413573342\n",
      "Initial log joint probability = -707.702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      62       58835.2   0.000370227       48510.7   7.273e-09       0.001      128  LS failed, Hessian reset \n",
      "      99       58845.4   3.93295e-08       52745.4      0.4956      0.4956      175   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     109       58845.4   8.40247e-09       46842.2      0.4521      0.4521      187   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30387\n",
      "mae: 3.9502082920552, mse: 24.155773180737015, r2: 0.7128285274690562\n",
      "Initial log joint probability = -579.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      85       59637.5   0.000130231       49746.8   2.689e-09       0.001      156  LS failed, Hessian reset \n",
      "      99       59640.9   8.99379e-07       49952.3      0.2989      0.2989      173   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     129       59641.2   4.26179e-09       51878.5      0.2137      0.2137      210   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "30794\n",
      "mae: 4.46125719369124, mse: 29.696620664603007, r2: 0.5100114640177873\n",
      "Initial log joint probability = -523.331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99         61688   3.65051e-07       49636.5      0.4955      0.4955      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     113       61688.1   7.14015e-09       47615.7      0.2014      0.2014      149   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "31800\n",
      "mae: 4.253910456041884, mse: 25.22258093513389, r2: 0.6324329012171589\n",
      "Initial log joint probability = -508.368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99         55813   1.10626e-06       48375.8      0.6389      0.6389      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     116         55813   3.68647e-09       50684.1      0.4696      0.4696      151   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "28783\n",
      "mae: 4.034270093432799, mse: 25.198643082838686, r2: 0.5047288777225095\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_best_WkMod_RegMod_Opt, \\\n",
    "    m_best_WkMod_RegMod_Opt, \\\n",
    "    ls_publish_best_WkMod_RegMod_Opt = my_pred_reg_wk(df=df_building,\n",
    "        model_name='Prophet Holidays-Wkl-Regressors-Optimized-Parameters - Tunning with MSE', \n",
    "        params=all_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "936a5df007153d01b3102aafced708416033fa212ee31eb346aae0df437c09f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
