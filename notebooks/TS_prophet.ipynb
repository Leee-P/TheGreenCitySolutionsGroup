{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS Prophet\n",
    "## Data split in training and test. The last 365 days are the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import cross\n",
    "import itertools\n",
    "from matplotlib import units\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "from green_city.utils import metrics_dict, datetime2index, index2datetime\n",
    "\n",
    "# Libraries to reduce Prophet verbose output\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLFLOW ##\n",
    "import mlflow\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "\n",
    "flow_conf = get_mlflow_config()\n",
    "tracking_uri = flow_conf[\"TRACKING_URI\"]\n",
    "mlflow.set_tracking_uri(flow_conf[\"TRACKING_URI\"])\n",
    "mlflow.set_experiment(flow_conf[\"EXPERIMENT_NAME\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_winter_season(ds):\n",
    "    \"\"\"Classifies the dates into Winter or Summer\n",
    "\n",
    "    Args:\n",
    "        ds (datetime series): A Pandas datetime series\n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(ds)\n",
    "    return(date.month < 4 or date.month > 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building = 5\n",
    "# # Load data\n",
    "# df_building = pd.read_csv(f\"../data/preprocessed/Building_{building}.csv\").astype({'datetime': 'datetime64'})#.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building = \"All\"\n",
    "# Load data\n",
    "df_building = pd.read_csv(f\"../data/preprocessed/Agg_buildings.csv\").astype({'datetime': 'datetime64'})#.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building = df_building.rename(columns={'datetime':'ds',\n",
    "                                    'net_load_kW':'y'})\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building.y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building['winter'] = df_building['ds'].apply(is_winter_season)\n",
    "df_building['summer'] = ~df_building['ds'].apply(is_winter_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holiday = df_building[['ds','holiday']].query('holiday')\n",
    "df_holiday['holiday'] = 'Holiday'\n",
    "# df_holiday\n",
    "\n",
    "## In the development stage, it was explored to add the workday as part of the  ##\n",
    "## seasonality. It did not had an effect. Including the holiday did.            ##\n",
    "# df_workday = df[['ds','workday']].query('workday')\n",
    "# df_workday['holiday'] = 'Workday'\n",
    "# df_workday = df_workday.drop('workday', axis=1)\n",
    "\n",
    "# df_holidays = pd.concat([df_holiday, df_workday], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "# pred_indices = [32135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet simple model. Three years training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_model_train = df_building[:365*3*24]\n",
    "df_simple_model_test = df_building[365*3*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prophed model. Specify 95% of uncertainty and additive model. (Default 80% and additive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_simple = Prophet(interval_width = 0.95, seasonality_mode=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_simple.fit(df_simple_model_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('../models/my_model_simple.json', 'w') as fout:\n",
    "    fout.write(model_to_json(my_model_simple))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting 8 days with basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params)\n",
    "            my_model.fit(df_train)\n",
    "\n",
    "            ## Save Model##\n",
    "            with open(f'../models/{model_name}_{index}.json', 'w') as fout:\n",
    "                fout.write(model_to_json(my_model_simple))  \n",
    "\n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "            \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            # forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MSE for tunning \n",
    "param_grid_simple = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.05],\n",
    "    'seasonality_prior_scale':[10.0],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.8]\n",
    "}\n",
    "my_simple_params = [dict(zip(param_grid_simple.keys(), v)) for v in itertools.product(*param_grid_simple.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mse_simpleMod, \\\n",
    "    my_model_simpleMod, \\\n",
    "    ls_publish_mse_simpleMod = my_pred(df = df_building,\n",
    "        model_name='Prophet Simple Model', \n",
    "        params=my_simple_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize modeling. Find best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prophet_find_hyperparameter(df, all_params):\n",
    "    \"\"\"Determine the best hyper parameters for a Prophet model.\n",
    "    It uses a base Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe): A pandas dataframe with the required Prophet structure\n",
    "        all_params (list of dictionaries): A list of dictionaries with the parameters definition. \n",
    "\n",
    "    Returns:\n",
    "        best_params: a list with the best parameters\n",
    "        tuning_results: A dataframe with the mse and rmse evaluation of the parameters combinations\n",
    "    \"\"\"\n",
    "    warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    logging.getLogger('prophet').setLevel(logging.ERROR) #Notice that i had modified the name from 'fbprophet' to just 'prophet'\n",
    "    mses = []\n",
    "    rmses = []\n",
    "    c=0\n",
    "    for params in all_params:\n",
    "        c =+ c\n",
    "        m = Prophet(**params)\n",
    "        m.fit(df)\n",
    "        ## Save Model##\n",
    "        with open(f'../models/Prophet_paramSearch_{c}.json', 'w') as fout:\n",
    "            fout.write(model_to_json(my_model_simple))  \n",
    "        df_cv = cross_validation(m, horizon='180 days', parallel='processes')\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        mses.append(df_p['mse'].values[0])\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['mse'] = mses\n",
    "    tuning_results['rmse'] = rmses\n",
    "    print(tuning_results)\n",
    "    best_params=all_params[np.argmin(mses)]\n",
    "    print(best_params)\n",
    "    return best_params, tuning_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter optimization. Tunning CV with MSE \n",
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001, 0.01, 0.05, 0.1, 0.5], #Parameters like this (regularization penalties; this is effectively a lasso penalty) are often tuned on a log scale.\n",
    "    'seasonality_prior_scale':[0.01, 0.1, 1.0, 10.0], #This likely also makes sense on a log scale, since it is effectively an L2 penalty like in ridge regression.\n",
    "    'holidays_prior_scale':[0.01, 0.1, 1.0, 10.0],\n",
    "    'changepoint_range':[0.8,0.9]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not run. It takes 95m. The results are in the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimized_parameters, \\\n",
    "    my_optimized_param_tunning_results = \\\n",
    "        my_prophet_find_hyperparameter(df_simple_model_train, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimized_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_optimized_parameters = {'interval_width': 0.95,\n",
    "#     'seasonality_mode': 'additive',\n",
    "#     'changepoint_prior_scale': 0.0001,\n",
    "#     'seasonality_prior_scale': 0.01,\n",
    "#     'holidays_prior_scale': 0.01,\n",
    "#     'changepoint_range': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the hyperparameters results from cross validation. RMSE and MSE are documented.\n",
    "# my_optimized_param_tunning_results\n",
    "# my_optimized_param_tunning_results.to_csv('../data/preprocessed/prophet_best_hyperparameters_bld_5.csv',\n",
    "#     sep=\";\", index_label='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hyperparameters results from cross validation. RMSE and MSE are documented.\n",
    "my_optimized_param_tunning_results\n",
    "my_optimized_param_tunning_results.to_csv('../data/preprocessed/prophet_best_hyperparameters_allbld.csv',\n",
    "    sep=\";\", index_label='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters that can be tuned\n",
    "\n",
    "**changepoint_prior_scale**: This is probably the most impactful parameter. It determines the flexibility of the trend, and in particular how much the trend changes at the trend changepoints. As described in this documentation, if it is too small, the trend will be underfit and variance that should have been modeled with trend changes will instead end up being handled with the noise term. If it is too large, the trend will overfit and in the most extreme case you can end up with the trend capturing yearly seasonality. The default of 0.05 works for many time series, but this could be tuned; a range of [0.001, 0.5] would likely be about right. Parameters like this (regularization penalties; this is effectively a lasso penalty) are often tuned on a log scale.\n",
    "\n",
    "**seasonality_prior_scale**: This parameter controls the flexibility of the seasonality. Similarly, a large value allows the seasonality to fit large fluctuations, a small value shrinks the magnitude of the seasonality. The default is 10., which applies basically no regularization. That is because we very rarely see overfitting here (there’s inherent regularization with the fact that it is being modeled with a truncated Fourier series, so it’s essentially low-pass filtered). A reasonable range for tuning it would probably be [0.01, 10]; when set to 0.01 you should find that the magnitude of seasonality is forced to be very small. This likely also makes sense on a log scale, since it is effectively an L2 penalty like in ridge regression.\n",
    "\n",
    "**holidays_prior_scale**: This controls flexibility to fit holiday effects. Similar to seasonality_prior_scale, it defaults to 10.0 which applies basically no regularization, since we usually have multiple observations of holidays and can do a good job of estimating their effects. This could also be tuned on a range of [0.01, 10] as with seasonality_prior_scale.\n",
    "\n",
    "**seasonality_mode**: Options are ['additive', 'multiplicative']. Default is 'additive', but many business time series will have multiplicative seasonality. This is best identified just from looking at the time series and seeing if the magnitude of seasonal fluctuations grows with the magnitude of the time series (see the documentation here on multiplicative seasonality), but when that isn’t possible, it could be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_simpleMod_Opt, \\\n",
    "        my_model_simpleMod_Opt, \\\n",
    "        ls_publish_simpleMod_Opt = my_pred(df = df_building,\n",
    "        model_name='Prophet Simple Model Optimized Parameters - Tunning with MSE', \n",
    "        params=my_optimized_parameters,\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_Opt_holidays, \\\n",
    "    m_best_Opt_holidays, \\\n",
    "    ls_publish_Opt_holidays = my_pred(df = df_building,\n",
    "        model_name='Prophet Holidays-Optimized-Parameters - Tunning with MSE', \n",
    "        params=my_optimized_parameters,\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add outdoor temperature, humidity, diffuse and direct solar energy as additional regressor. \n",
    "### The temperature, humidity and solar energy data is in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_reg(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params)\n",
    "            my_model.add_regressor(name='outdoor_temp')\n",
    "            my_model.add_regressor(name='outdoor_hum')\n",
    "            my_model.add_regressor(name='diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='direct_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_temp')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_hum')\n",
    "            my_model.add_regressor(name='pred_24h_diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_direct_solar_W_m2')\n",
    "            my_model.fit(df_train) \n",
    "\n",
    "            ## Save Model##\n",
    "            with open(f'../models/{model_name}_{index}.json', 'w') as fout:\n",
    "                fout.write(model_to_json(my_model_simple))  \n",
    "            \n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "                 \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            # forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_best_WkMod_RegMod_Opt, \\\n",
    "    m_best_RegMod_Opt, \\\n",
    "    ls_publish_best_RegMod_Opt = my_pred_reg(df=df_building,\n",
    "        model_name='Prophet Holidays-Regressors-Optimized-Parameters - Tunning with MSE', \n",
    "        params=all_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop. The following results are dubious at the moment. (01.08.2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume different weekly sesonalities. Summer vs Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_reg_wk(df,model_name, params, pred_index):\n",
    "    \"\"\"Forecast a specified interval into a Prophet model. \n",
    "\n",
    "    Args:\n",
    "        df (dataframe)    : A pandas dataframe with the form required by Prophet. Must include the training and testing data.\n",
    "        model_name (str)  : A string with a unique description of the model to evaluate.\n",
    "        params(list) : A list of dictionaries with the parameters definition. \n",
    "        pred_index (list) : A list with the indexes of the intervals to predict. (\"Test data\"). These indexes must exist in the df variable.\n",
    "\n",
    "    Returns:\n",
    "        forecasts (dataframe)           : A dataframe with the forecasted values from the interval of interest. \n",
    "        ls_best_params (list)           : A list with the best hyperpameters and its evaluation metrics; mse and rsme.\n",
    "        my_model(fitted Prophet model)  : A fitted prophet model. The model utilized to forecast the data. \n",
    "        ls_publish                      : A list with the information to put in mlflow and the SQL server. Includes the forecasts dataframe,\n",
    "                                          the msa, mse and r2_score.\n",
    "    \"\"\"\n",
    "\n",
    "    # ls_best_params = []\n",
    "    ls_publish = []\n",
    "    for index in pred_index:\n",
    "        df_train=df.loc[:index] # dataframe to train the model and its optimization (this was a mistake)\n",
    "        df_future = df.loc[index+1:index+24]\n",
    "        with mlflow.start_run(run_name=model_name) as r:\n",
    "            ### Predict ##\n",
    "            # best_params, tuning_results = my_prophet_mse(df_train, all_params=parameters) # The optimized parameters are coming form the 3 years training data\n",
    "            # ls_best_params.append([{'index':index}, best_params, tuning_results]) # This is not required anymore.\n",
    "            my_model = Prophet(**params, weekly_seasonality=False)\n",
    "            my_model.add_regressor(name='outdoor_temp')\n",
    "            my_model.add_regressor(name='outdoor_hum')\n",
    "            my_model.add_regressor(name='diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='direct_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_temp')\n",
    "            my_model.add_regressor(name='pred_24h_outdoor_hum')\n",
    "            my_model.add_regressor(name='pred_24h_diffuse_solar_W_m2')\n",
    "            my_model.add_regressor(name='pred_24h_direct_solar_W_m2')\n",
    "            my_model.add_seasonality(name='weekly_on_winter', period = 7, fourier_order= 10, condition_name='winter')\n",
    "            my_model.add_seasonality(name='weekly_on_summer', period = 7, fourier_order= 10, condition_name='summer')\n",
    "            my_model.fit(df_train) \n",
    "\n",
    "            ## Save Model##\n",
    "            with open(f'../models/{model_name}_{index}.json', 'w') as fout:\n",
    "                fout.write(model_to_json(my_model_simple))  \n",
    "\n",
    "            df_forecast = my_model.predict(df_future)\n",
    "            df_forecast.index = df_future.index\n",
    "            df_forecast.index.name = 'id'\n",
    "            df_forecast['error'] = df_future.y - df_forecast.yhat\n",
    "            df_forecast = df_forecast[['yhat', 'error']]\n",
    "            \n",
    "            ## Evaluate ##\n",
    "            metrics = metrics_dict(df_future.y, df_forecast.yhat, [\"mae\", \"mse\", \"r2_score\"])\n",
    "            print(index)\n",
    "            print(\"mae: {mae}, mse: {mse}, r2: {r2_score}\".format(**metrics))\n",
    "            # print(ls_best_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            ## Parameters log ##\n",
    "            mlflow_params = {\n",
    "                'building_nr': building,\n",
    "                'datetime':index2datetime(index)\n",
    "            }\n",
    "            mlflow.log_params(mlflow_params)\n",
    "\n",
    "            forecasts = df_forecast[['yhat']].assign(run_id = r.info.run_id).rename(columns={\"yhat\": \"prediction\"})\n",
    "            # forecasts.to_sql(\"forecast\", con=db, if_exists=\"append\")\n",
    "            ls_publish.append([{'index':index,'metrics':metrics, 'params':params, 'forecast':forecasts}])\n",
    "    return forecasts, my_model, ls_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'interval_width': [0.95],\n",
    "    'seasonality_mode':['additive'],\n",
    "    'changepoint_prior_scale':[0.0001],\n",
    "    'seasonality_prior_scale':[0.01],\n",
    "    'holidays_prior_scale':[0.01],\n",
    "    'changepoint_range':[0.9],\n",
    "    'holidays':[df_holiday]\n",
    "}\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pred_best_WkMod_RegMod_Opt, \\\n",
    "    m_best_WkMod_RegMod_Opt, \\\n",
    "    ls_publish_best_WkMod_RegMod_Opt = my_pred_reg_wk(df=df_building,\n",
    "        model_name='Prophet Holidays-Wkl-Regressors-Optimized-Parameters - Tunning with MSE', \n",
    "        params=all_params[0],\n",
    "        pred_index=pred_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "936a5df007153d01b3102aafced708416033fa212ee31eb346aae0df437c09f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
