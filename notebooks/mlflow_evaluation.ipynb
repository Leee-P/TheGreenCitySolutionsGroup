{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.dates import DateFormatter\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from pydash import py_\n",
    "from green_city.utils import datetime2index, index2datetime\n",
    "\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "mlflow.set_tracking_uri(get_mlflow_config()[\"TRACKING_URI\"])\n",
    "client = MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(\"green_city_experiments\").experiment_id\n",
    "\n",
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global configuration\n",
    "BUILDING_NR = \"all\"\n",
    "USE_ROOT = True #RMSE insead of MSE\n",
    "\n",
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "INDEX_LINEPLOT = indices[7]\n",
    "\n",
    "##########################################################\n",
    "#df.loc[df[\"run_name\"] == \"Prophet Simple Model\", \"model\"] = \"prophet\"\n",
    "#df.loc[df[\"run_name\"] == \"Prophet Simple Model Optimized Parameters\", \"model\"] = \"prophet\"\n",
    "#    if df_row[\"run_name\"] == \"Prophet Simple Model\":\n",
    "#        return \"Prophet\"\n",
    "#df[df[\"run_name\"] == \"Prophet Simple Model\"].index\n",
    "##########################################################\n",
    "#    plot_df = plot_df[plot_df[\"run_name\"] != \"sarimax_(6,1,1)(0,0,2,24)\"]\n",
    "#    plot_df = plot_df[plot_df[\"disp_label\"].map(lambda x: x in (\"Linear regression\", \"Sarimax\", \"Prophet\", \"TBATS\", \"ARIMA\", \"Baseline\"))]\n",
    "##########################################################\n",
    "\n",
    "\n",
    "selectors = {\n",
    "    'baseline': {\n",
    "        'select__model': 'baseline',\n",
    "        'disp_color': 'orange',\n",
    "        'disp_label': 'Baseline',\n",
    "    },\n",
    "    'linear_regression': {\n",
    "        'select__run_name': 'linear_regression', #wouldn't need both selectors actually\n",
    "        'select__model': 'linear_regression',\n",
    "        'disp_color': '#7BC8F6',\n",
    "        'disp_label': 'Linear regression',\n",
    "    },\n",
    "    'tbats': {\n",
    "        'select__run_name': 'TBATS_1000',\n",
    "        'select__model': 'TBATS',\n",
    "        'disp_color': 'blue',\n",
    "        'disp_label': 'TBATS',\n",
    "    },\n",
    "    #'arima': {\n",
    "    #    'select__model': 'ARIMA',\n",
    "    #    'disp_color': 'purple',\n",
    "    #    'disp_label': 'ARIMA',\n",
    "    #},\n",
    "    'sarimax': {\n",
    "        'select__model': 'sarimax',\n",
    "        'exclude__run_name': 'sarimax_(6,1,1)(0,0,2,24)',\n",
    "        'disp_color': '#FF7F50',\n",
    "        'disp_label': 'SARIMAX',\n",
    "    },\n",
    "    'prophet_1': {\n",
    "        'select__run_name': 'Prophet Holidays-Wkl-Regressors-Optimized-Parameters - Tunning with MSE',\n",
    "        'disp_color': 'purple',\n",
    "        'disp_label': 'Prophet',\n",
    "    },\n",
    "    #'prophet_2': {\n",
    "    #    'select__run_name': 'Prophet Holidays-Regressors-Optimized-Parameters - Tunning with MSE',\n",
    "    #    'disp_color': 'purple',\n",
    "    #    'disp_label': 'Prophet 2',\n",
    "    #},\n",
    "    #'prophet_3': {\n",
    "    #    'select__run_name': 'Prophet Holidays-Optimized-Parameters - Tunning with MSE',\n",
    "    #    'disp_color': 'purple',\n",
    "    #    'disp_label': 'Prophet 3',\n",
    "    #},\n",
    "    #'prophet_4': {\n",
    "    #    'select__run_name': 'Prophet Simple Model Optimized Parameters - Tunning with MSE',\n",
    "    #    'disp_color': 'purple',\n",
    "    #    'disp_label': 'Prophet 4',\n",
    "    #},\n",
    "    #'prophet_5': {\n",
    "    #    'select__run_name': 'Prophet Simple Model',\n",
    "    #    'disp_color': 'purple',\n",
    "    #    'disp_label': 'Prophet 5',\n",
    "    #},\n",
    "    'random_forest': {\n",
    "        'select__run_name': 'random_forest',\n",
    "        'disp_color': 'green',\n",
    "        'disp_label': 'Random forest',\n",
    "    },\n",
    "    'poly_regression': {\n",
    "        'select__run_name': 'poly_regression',\n",
    "        'disp_color': '#FFD700',\n",
    "        'disp_label': 'Polynomial regression',\n",
    "    },\n",
    "    'xgb_optimized': {\n",
    "        'select__run_name': 'XGB_optimized',\n",
    "        'disp_color': '#06C2AC',\n",
    "        'disp_label': 'XGBoost',\n",
    "    },\n",
    "    #'xgb_simple': {\n",
    "    #    'select__run_name': 'XGB_simple',\n",
    "    #    'disp_color': 'cyan',\n",
    "    #    'disp_label': 'XGB simple',\n",
    "    #},\n",
    "}\n",
    "\n",
    "def select(run_info):\n",
    "    for name, di in selectors.items():\n",
    "        is_match = True\n",
    "        for select_key in filter(lambda x: 'select__' in x, di.keys()):\n",
    "            key = select_key.split('__')[1]\n",
    "            if run_info.get(key) != di[select_key]:\n",
    "                is_match = False\n",
    "                break\n",
    "        for exclude_key in filter(lambda x: 'exclude__' in x, di.keys()):\n",
    "            key = exclude_key.split('__')[1]\n",
    "            if run_info.get(key) == di[exclude_key]:\n",
    "                is_match = False\n",
    "                break\n",
    "        if is_match:\n",
    "            return (name, dict([(k, v) for k, v in di.items() if k in ['disp_color', 'disp_label'] ]))\n",
    "    return (None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [r.run_id for r in client.list_run_infos(experiment_id, run_view_type=ViewType.ACTIVE_ONLY)]\n",
    "\n",
    "all_runs = {run_id: client.get_run(run_id).to_dictionary() for run_id in run_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dict = {}\n",
    "\n",
    "for id, details in all_runs.items():\n",
    "    start_time = py_.get(details, \"info.start_time\")\n",
    "    end_time = py_.get(details, \"info.end_time\")\n",
    "    #delta = round(end_time/1000 - start_time/1000, 2)\n",
    "\n",
    "    #filter by buildings\n",
    "    params = py_.get(details, \"data.params\")\n",
    "\n",
    "    if len(params) == 0: #probably currently active run\n",
    "        continue\n",
    "    \n",
    "    runs_dict_id = {\n",
    "        #\"time_s\": delta,\n",
    "        **py_.get(details, \"data.metrics\"),\n",
    "        **py_.get(details, \"data.params\"),\n",
    "        \"run_name\": details[\"data\"][\"tags\"][\"mlflow.runName\"],\n",
    "    }\n",
    "\n",
    "    if (runs_dict_id.get(\"building nr\") and not runs_dict_id.get(\"building_nr\")):\n",
    "        runs_dict_id[\"building_nr\"] = runs_dict_id.pop(\"building nr\")\n",
    "    \n",
    "    assert 'building nr' not in runs_dict_id.keys()\n",
    "    assert 'building_nr' in runs_dict_id.keys()\n",
    "\n",
    "    #selection 1: building nr\n",
    "    if BUILDING_NR is not None:\n",
    "        if BUILDING_NR.lower() != runs_dict_id['building_nr'].lower():\n",
    "            continue\n",
    "\n",
    "    #selection 2: models to include\n",
    "    selection_name, additional_properties = select(runs_dict_id)\n",
    "    if selection_name is not None:\n",
    "        runs_dict_id.update(additional_properties)\n",
    "        runs_dict_id[\"name\"] = selection_name\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    runs_dict[id] = runs_dict_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(runs_dict, orient='index')\n",
    "df = df.astype({\"datetime\": \"datetime64[ns]\"})\n",
    "df = df.assign(index = df['index'].fillna(df.datetime.map(datetime2index))).dropna(subset=[\"index\"])\n",
    "\n",
    "#if index is not set, assign it from datetime\n",
    "df.datetime.map(datetime2index).unique()\n",
    "df = df.astype({\"index\": \"int\", \"train_steps\": \"float\"})\n",
    "df.index = df.index.rename(\"run_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = [25, 8]\n",
    "#df[df.feature==\"net_load_kWh\"].loc[:, [\"mae\", \"mse\", \"r2_score\"]].plot.barh()\n",
    "#df[df.feature==\"net_load_kWh\"].loc[:, [\"time_s\"]].plot.barh()\n",
    "df.to_csv(\"../data/results/evaluation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "\n",
    "#TODO: take keys from selection dictionary or from actual used names.\n",
    "#all_performances = {\n",
    "#    \"baseline\": [],\n",
    "#    \"linear_regression\": [],\n",
    "#    \"TBATS\": [],\n",
    "#    \"sarimax\": [],\n",
    "#    \"ARIMA\": [],\n",
    "#    \"prophet\": [],\n",
    "#}\n",
    "all_performances = {k: [] for k in selectors.keys()}\n",
    "\n",
    "all_performances_dicts = []\n",
    "\n",
    "\n",
    "for index in indices:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(2)\n",
    "    fig.set_figwidth(5)\n",
    "    fig.set_dpi(240)\n",
    "\n",
    "    plot_df = (df[df[\"index\"] == index]\n",
    "                .sort_values(\"mse\", ascending=False)\n",
    "                #.assign(col = lambda x:x[\"model\"].map(lambda x: model2color.get(x, \"black\")))\n",
    "                #.assign(label = lambda x: f\"{x['model']}{steps2str(x['train_steps'])}\")\n",
    "                .drop_duplicates(subset=[\"run_name\", \"model\"])\n",
    "    )\n",
    "    plot_df[\"rmse\"] = np.sqrt(plot_df[\"mse\"])\n",
    "\n",
    "    \n",
    "    for idx, benchmark in plot_df.iterrows():\n",
    "        all_performances[benchmark[\"name\"]].append(benchmark[\"mse\"])\n",
    "        all_performances_dicts.append({\n",
    "            'model': [benchmark['name']],\n",
    "            'time_index': [index],\n",
    "            'run_index': [idx],\n",
    "            'mse': [benchmark['mse']],\n",
    "            'mae': [benchmark['mae']],\n",
    "            'rmse': [benchmark['rmse']],\n",
    "        })\n",
    "    \n",
    "    if USE_ROOT:\n",
    "        score_col = \"rmse\"\n",
    "    else:\n",
    "        score_col = \"mse\"\n",
    "    plot_df.plot.barh(x=\"disp_label\", y=score_col, color=plot_df[\"disp_color\"], legend=None, ax=ax)\n",
    "    #ax.barh(plot_df[\"mse\"], width=20, color=plot_df[\"col\"], legend=None, height=0.9)\n",
    "    axis_label = \"Root Mean Squared Error\" if USE_ROOT else \"Mean squared error\"\n",
    "    ax.set_xlabel(axis_label)\n",
    "    ax.set_ylabel(None)\n",
    "    #fig.suptitle(f\"{str(index2datetime(index+1))} to {str(index2datetime(index+24))}\")\n",
    "    fig.suptitle(\"\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "all_performances_df = pd.DataFrame({\n",
    "    'model': [],\n",
    "    'time_index': [],\n",
    "    'mse': [],\n",
    "    'mae': [],\n",
    "    'rmse': [],\n",
    "})\n",
    "all_performances_df = pd.concat([pd.DataFrame(di) for di in all_performances_dicts], ignore_index=True)\n",
    "all_performances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performances_df[\"disp_color\"] = all_performances_df.model.map(lambda x: selectors[x][\"disp_color\"])\n",
    "all_performances_df[\"disp_label\"] = all_performances_df.model.map(lambda x: selectors[x][\"disp_label\"])\n",
    "all_performances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import xlabel\n",
    "\n",
    "agg_performances = all_performances_df.groupby(\"model\").mean().sort_values(\"rmse\", ascending=False)\n",
    "agg_performances[\"disp_color\"] = agg_performances.index.map(lambda x: selectors[x][\"disp_color\"])\n",
    "agg_performances[\"disp_label\"] =  agg_performances.index.map(lambda x: selectors[x][\"disp_label\"])\n",
    "baseline_score = agg_performances[agg_performances.index == \"baseline\"][\"rmse\"].values[0]\n",
    "baseline_score_mse = agg_performances[agg_performances.index == \"baseline\"][\"mse\"].values[0]\n",
    "baseline_score_mae = agg_performances[agg_performances.index == \"baseline\"][\"mae\"].values[0]\n",
    "agg_performances[\"relative_rmse\"] = agg_performances.rmse.map(lambda x: x/baseline_score)\n",
    "agg_performances[\"relative_mse\"] = agg_performances.mse.map(lambda x: x/baseline_score_mse)\n",
    "agg_performances[\"relative_mae\"] = agg_performances.mae.map(lambda x: x/baseline_score_mae)\n",
    "agg_performances\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "agg_performances.plot.barh(\n",
    "    x=\"disp_label\",\n",
    "    #y=\"relative_mse\",\n",
    "    y=\"relative_mae\",\n",
    "    #label=\"relative_rmse\",\n",
    "    color=agg_performances.disp_color,\n",
    "    title=\"Mean absolute error (lower is better)\",\n",
    "    xlabel=\"\",\n",
    "    legend=None,\n",
    "    ax=ax);\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "for i, (model_index, model_info) in enumerate(agg_performances.iterrows()):\n",
    "    if model_index == \"baseline\":\n",
    "        continue\n",
    "    x = model_info.relative_mae\n",
    "    y = i\n",
    "    #ax.text(x+0.01, y-0.1, f\"{100*model_info.relative_mae:.0f}%\", color=model_info.disp_color, size=14)\n",
    "    ax.text(x+0.01, y-0.18, f\"{100*model_info.relative_mae:.0f}%\", color=\"black\", size=12)\n",
    "\n",
    "fig.set_dpi(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_performance = {}\n",
    "for k, v in all_performances.items():\n",
    "    #if k == \"ARIMA\":\n",
    "    #    continue\n",
    "    #print(k, v)\n",
    "    #avg_performance[k] = [0]\n",
    "    avg_performance[k] = np.mean(v) #TODO: check if I am overwriting sth here\n",
    "mmses = pd.concat([pd.DataFrame({\"model\": [k], \"mmse\": [v]}) for k, v in avg_performance.items()], axis=0)\n",
    "mmses = mmses.sort_values(\"mmse\", ascending=False)\n",
    "\n",
    "#mmses[\"color\"] = mmses.model.map(lambda x: model2color.get(x, \"black\"))\n",
    "mmses[\"color\"] = mmses.model.map(lambda x: selectors[x][\"disp_color\"])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(9)\n",
    "fig.set_dpi(240)\n",
    "\n",
    "mmses[\"disp_label\"] = mmses.model.map(lambda x: selectors[x][\"disp_label\"])\n",
    "\n",
    "mmses.plot.barh(x=\"disp_label\", y=\"mmse\", color=mmses[\"color\"], ax=ax)\n",
    "ax.set_xlabel(\"Average performance (Mean Squared Error)\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend().remove()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual dataset\n",
    "def get_df(building_nr, feature):\n",
    "    if building_nr == \"all\":\n",
    "        filename = \"Agg_buildings.csv\"\n",
    "    else:\n",
    "        filename = f\"Building_{building_nr}.csv\"\n",
    "    df = (\n",
    "    pd.read_csv(Path(\"../data/preprocessed\") / filename)\n",
    "        .astype({'datetime': 'datetime64'})\n",
    "        [[feature, \"datetime\"]]\n",
    "        .rename(columns={feature: \"actual\"})\n",
    "    )\n",
    "    df.index.name = \"id\"\n",
    "    return df\n",
    "\n",
    "actual_df = get_df(BUILDING_NR, \"net_load_kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25, 6]\n",
    "\n",
    "#index_to_plot = INDEX_LINEPLOT\n",
    "index_to_plot = indices[2] #2 or 3\n",
    "#index_to_plot = indices[1]\n",
    "plot_performances = all_performances_df[all_performances_df[\"time_index\"] == index_to_plot]\n",
    "plot_df = df[df[\"index\"] == index_to_plot].drop_duplicates(subset=[\"run_name\"])\n",
    "#display(plot_df)\n",
    "#display(plot_performances)\n",
    "#print(plot_performances.shape)\n",
    "#display(all_performances_df)\n",
    "#print(all_performances_df.shape)\n",
    "from pandas import concat\n",
    "\n",
    "df_from_csv_1 = pd.read_csv(\"../data/results/linear_regression.csv\")\n",
    "df_from_csv_2 = pd.read_csv(\"../data/results/sarimax_(2,1,1)(1,0,1,24).csv\")\n",
    "df_from_csv = pd.concat([df_from_csv_1, df_from_csv_2], axis=0, ignore_index=True)[[\"runid\", \"id\", \"prediction\"]].rename(columns={\"runid\": \"run_id\"})\n",
    "#df_from_csv.head()\n",
    "\n",
    "y_true = actual_df.loc[index_to_plot+1:index_to_plot+24].set_index(\"datetime\")\n",
    "\n",
    "fig = plt.figure(figsize=(11,3), dpi=240)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for run_id, run_data in plot_performances.set_index(\"run_index\").iterrows():\n",
    "    if not run_data[\"model\"] in [\"random_forest\", \"prophet_1\"]:\n",
    "        continue\n",
    "#for run_id, run_data in plot_df.iterrows():\n",
    "    plot_kwargs = {}\n",
    "    query_string = f\"SELECT * FROM forecast WHERE run_id='{run_id}'\" # LIMIT 10\"\n",
    "    run_predictions = pd.read_sql(query_string, db).drop(columns=\"run_id\")\n",
    "    if len(run_predictions) == 0:\n",
    "        print(f\"[INFO: for {run_id}, there is not data in the SQL database.]\")\n",
    "        #print(f\"[...trying to read from csv file]\")\n",
    "        run_predictions = df_from_csv[df_from_csv.run_id == run_id].copy().drop(columns=\"run_id\")\n",
    "        if len(run_predictions) == 0:\n",
    "            print(f\"[Warning: didn't find {run_id} csv data]\")\n",
    "            continue\n",
    "        #TODO: include plot style in selectors dict\n",
    "        #if run_data.run_name in [\"linear_regression\", \"sarimax_(2,1,1)(1,0,1,24)\"]:\n",
    "        if run_data.model in [\"linear_regression\", \"sarimax_(2,1,1)(1,0,1,24)\"]:\n",
    "            plot_kwargs = {\n",
    "                'linestyle': 'dashed'\n",
    "            }\n",
    "\n",
    "    run_predictions[\"datetime\"] = run_predictions[\"id\"].map(index2datetime)#y_true.index\n",
    "    #color = selectors[run_data['name']].get(\"disp_color\")\n",
    "    ax.plot(run_predictions.drop(columns=[\"id\"]).set_index(\"datetime\"), color=run_data[\"disp_color\"], label=run_data[\"disp_label\"], **plot_kwargs)\n",
    "\n",
    "ax.plot(y_true, color=\"black\", linestyle=\"dashed\", label=\"Actual data\");\n",
    "#plt.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "ax.legend(prop={'size': 9})\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return f\"{int(x)} kW\"\n",
    "\n",
    "#ax.set_ylim(21, 82)\n",
    "#ax.set_ylim(0, 62)\n",
    "#if BUILDING_NR == 'all':\n",
    "#    ax.set_ylim(-50, 500)\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "date_form = DateFormatter(\"%H:%M\")\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "#fig.suptitle(\"Net energy usage forecasts (Year 4, Sep 2)\")\n",
    "fig.suptitle(\"Energy demand forecasts (Year 4, Apr 15 - 16)\")\n",
    "ax.legend(bbox_to_anchor=(1,0), loc=\"lower left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adec6c5f7a7e6b374924807d676c9e580fd19dbf1c8cad640c4c5a1bb48bcada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
