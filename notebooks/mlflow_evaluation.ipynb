{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from datetime import datetime, timedelta\n",
    "from pydash import py_\n",
    "from green_city.utils import datetime2index, index2datetime\n",
    "\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "mlflow.set_tracking_uri(get_mlflow_config()[\"TRACKING_URI\"])\n",
    "client = MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(\"green_city_experiments\").experiment_id\n",
    "\n",
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [r.run_id for r in client.list_run_infos(experiment_id, run_view_type=ViewType.ACTIVE_ONLY)]\n",
    "\n",
    "all_runs = {run_id: client.get_run(run_id).to_dictionary() for run_id in run_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dict = {}\n",
    "\n",
    "for id, details in all_runs.items():\n",
    "    start_time = py_.get(details, \"info.start_time\")\n",
    "    end_time = py_.get(details, \"info.end_time\")\n",
    "    #delta = round(end_time/1000 - start_time/1000, 2)\n",
    "    runs_dict[id] = {\n",
    "        #\"time_s\": delta,\n",
    "        **py_.get(details, \"data.metrics\"),\n",
    "        **py_.get(details, \"data.params\"),\n",
    "        \"run_name\": details[\"data\"][\"tags\"][\"mlflow.runName\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(runs_dict, orient='index')\n",
    "df = df.astype({\"datetime\": \"datetime64[ns]\"})\n",
    "df = df.assign(index = df['index'].fillna(df.datetime.map(datetime2index))).dropna(subset=[\"index\"])\n",
    "\n",
    "#if index is not set, assign it from datetime\n",
    "df.datetime.map(datetime2index).unique()\n",
    "df = df.astype({\"index\": \"int\", \"train_steps\": \"float\"})\n",
    "df.index = df.index.rename(\"run_id\")\n",
    "\n",
    "#Drop the shorter TBATS models\n",
    "df = df[np.logical_or(np.logical_not(df.train_steps<1000), df.model!=\"TBATS\")]\n",
    "df = df[df.model!=\"ARIMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"run_name\"] == \"Prophet Simple Model\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = [25, 8]\n",
    "#df[df.feature==\"net_load_kWh\"].loc[:, [\"mae\", \"mse\", \"r2_score\"]].plot.barh()\n",
    "#df[df.feature==\"net_load_kWh\"].loc[:, [\"time_s\"]].plot.barh()\n",
    "df.to_csv(\"../data/results/evaluation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_label(df_row):\n",
    "    if df_row[\"run_name\"] == \"Prophet Simple Model\":\n",
    "        return \"Prophet\"\n",
    "    \n",
    "    if df_row[\"model\"] == \"TBATS\":\n",
    "        return df_row['model']\n",
    "        #if not np.isnan(df_row[\"train_steps\"]):\n",
    "        #    return df_row['model'] + \" (\" + str(int(df_row['train_steps'])) + \" trainsteps)\"\n",
    "        #else:\n",
    "        #    return df_row['model']\n",
    "    elif df_row[\"model\"] == \"sarimax\":\n",
    "        return \"Sarimax\"\n",
    "        # return df_row[\"run_name\"].capitalize().replace(\"_\", \" \")\n",
    "    elif df_row[\"model\"] == \"baseline\":\n",
    "        return \"Baseline\"\n",
    "    elif df_row[\"model\"] == \"linear_regression\":\n",
    "        return \"Linear regression\"\n",
    "    else:\n",
    "        return df_row[\"model\"]\n",
    "    \n",
    "df.loc[df[\"run_name\"] == \"Prophet Simple Model\", \"model\"] = \"prophet\"\n",
    "df.loc[df[\"run_name\"] == \"Prophet Simple Model Optimized Parameters\", \"model\"] = \"prophet\"\n",
    "\n",
    "\n",
    "df[\"disp_label\"] = df.apply(row_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "USE_ROOT = True\n",
    "   \n",
    "model2color = {\n",
    "    \"baseline\": \"orange\",\n",
    "    \"linear_regression\": \"gray\",\n",
    "    \"TBATS\": \"blue\",\n",
    "    \"sarimax\": \"green\",\n",
    "    \"ARIMA\": \"purple\",\n",
    "    \"prophet\": \"purple\",\n",
    "}\n",
    "\n",
    "all_performances = {\n",
    "    \"baseline\": [],\n",
    "    \"linear_regression\": [],\n",
    "    \"TBATS\": [],\n",
    "    \"sarimax\": [],\n",
    "    \"ARIMA\": [],\n",
    "    \"prophet\": [],\n",
    "}\n",
    "\n",
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "for index in indices:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(2)\n",
    "    fig.set_figwidth(5)\n",
    "    fig.set_dpi(240)\n",
    "\n",
    "    plot_df = (df[df[\"index\"] == index]\n",
    "                .sort_values(\"mse\", ascending=False)\n",
    "                .assign(col = lambda x:x[\"model\"].map(lambda x: model2color.get(x, \"black\")))\n",
    "                #.assign(label = lambda x: f\"{x['model']}{steps2str(x['train_steps'])}\")\n",
    "                .drop_duplicates(subset=[\"run_name\"])\n",
    "    )\n",
    "    plot_df[\"rmse\"] = np.sqrt(plot_df[\"mse\"])\n",
    "    \n",
    "    plot_df = plot_df[plot_df[\"run_name\"] != \"sarimax_(6,1,1)(0,0,2,24)\"]\n",
    "    plot_df = plot_df[plot_df[\"disp_label\"].map(lambda x: x in (\"Linear regression\", \"Sarimax\", \"Prophet\", \"TBATS\", \"ARIMA\", \"Baseline\"))]\n",
    "    \n",
    "    for idx, benchmark in plot_df.iterrows():\n",
    "        all_performances[benchmark[\"model\"]].append(benchmark[\"mse\"])\n",
    "    \n",
    "    if USE_ROOT:\n",
    "        score_col = \"rmse\"\n",
    "    else:\n",
    "        score_col = \"mse\"\n",
    "    plot_df.plot.barh(x=\"disp_label\", y=score_col, color=plot_df[\"col\"], legend=None, ax=ax)\n",
    "    #ax.barh(plot_df[\"mse\"], width=20, color=plot_df[\"col\"], legend=None, height=0.9)\n",
    "    axis_label = \"Root Mean Squared Error\" if USE_ROOT else \"Mean squared error\"\n",
    "    ax.set_xlabel(axis_label)\n",
    "    ax.set_ylabel(None)\n",
    "    #fig.suptitle(f\"{str(index2datetime(index+1))} to {str(index2datetime(index+24))}\")\n",
    "    fig.suptitle(\"\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_performance = {}\n",
    "for k, v in all_performances.items():\n",
    "    if k == \"ARIMA\":\n",
    "        continue\n",
    "    #print(k, v)\n",
    "    #avg_performance[k] = [0]\n",
    "    avg_performance[k] = np.mean(v)\n",
    "display(avg_performance)\n",
    "mmses = pd.concat([pd.DataFrame({\"model\": [k], \"mmse\": [v]}) for k, v in avg_performance.items()], axis=0)\n",
    "mmses = mmses.sort_values(\"mmse\", ascending=False)\n",
    "mmses[\"color\"] = mmses.model.map(lambda x: model2color.get(x, \"black\"))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(9)\n",
    "fig.set_dpi(240)\n",
    "\n",
    "mmses.plot.barh(x=\"model\", y=\"mmse\", color=mmses[\"color\"], ax=ax)\n",
    "ax.set_xlabel(\"Average performance (Mean Squared Error)\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend().remove()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual dataset\n",
    "def get_df(building_nr, feature):\n",
    "    df = (\n",
    "    pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\")\n",
    "        .astype({'datetime': 'datetime64'})\n",
    "        [[feature, \"datetime\"]]\n",
    "        .rename(columns={feature: \"actual\"})\n",
    "    )\n",
    "    df.index.name = \"id\"\n",
    "    return df\n",
    "\n",
    "actual_df = get_df(5, \"net_load_kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25, 6]\n",
    "\n",
    "index_to_plot = indices[7]\n",
    "#index_to_plot = indices[1]\n",
    "plot_df = df[df[\"index\"] == index_to_plot].drop_duplicates(subset=[\"run_name\"])\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "\n",
    "\n",
    "df_from_csv_1 = pd.read_csv(\"../data/results/linear_regression.csv\")\n",
    "df_from_csv_2 = pd.read_csv(\"../data/results/sarimax_(2,1,1)(1,0,1,24).csv\")\n",
    "df_from_csv = pd.concat([df_from_csv_1, df_from_csv_2], axis=0, ignore_index=True)[[\"runid\", \"id\", \"prediction\"]].rename(columns={\"runid\": \"run_id\"})\n",
    "#df_from_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def y_fmt(x, y):\n",
    "#    if max_y > 1000000:\n",
    "#        val = int(y)/1000000\n",
    "#        return '{:d} M'.format(val)\n",
    "#    elif max_y > 1000:\n",
    "#        val = int(y) / 1000\n",
    "#        return '{:d} k'.format(val)\n",
    "#    else:\n",
    "#        return y\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "y_true = actual_df.loc[index_to_plot+1:index_to_plot+24].set_index(\"datetime\")\n",
    "\n",
    "fig = plt.figure(figsize=(11,3), dpi=240)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for run_id, run_data in plot_df.iterrows():\n",
    "    plot_kwargs = {}\n",
    "    query_string = f\"SELECT * FROM forecast WHERE run_id='{run_id}'\" # LIMIT 10\"\n",
    "    run_predictions = pd.read_sql(query_string, db).drop(columns=\"run_id\")\n",
    "    if len(run_predictions) == 0:\n",
    "        #print(f\"[INFO: for {run_id}, there is not data in the SQL database.]\")\n",
    "        #print(f\"[...trying to read from csv file]\")\n",
    "        run_predictions = df_from_csv[df_from_csv.run_id == run_id].copy().drop(columns=\"run_id\")\n",
    "        if len(run_predictions) == 0:\n",
    "            print(f\"[Warning: didn't find {run_id} csv data]\")\n",
    "            continue\n",
    "        if run_data.run_name in [\"linear_regression\", \"sarimax_(2,1,1)(1,0,1,24)\"]:\n",
    "            plot_kwargs = {\n",
    "                'linestyle': 'dashed'\n",
    "            }\n",
    "\n",
    "    run_predictions[\"datetime\"] = run_predictions[\"id\"].map(index2datetime)#y_true.index\n",
    "    color = model2color.get(run_data.model, \"gray\")\n",
    "    ax.plot(run_predictions.drop(columns=[\"id\"]).set_index(\"datetime\"), color=color, label=run_data[\"disp_label\"], **plot_kwargs)\n",
    "    #ax.plot(run_predictions.drop(columns=[\"id\"]).set_index(\"datetime\"), color=color, label=run_data[\"disp_label\"])\n",
    "ax.plot(y_true, color=\"black\", label=\"actual data\");\n",
    "#plt.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "ax.legend(prop={'size': 9})\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return f\"{int(x)} kW\"\n",
    "    #return f\"x:{x}; y:{y}\"\n",
    "    #return '{:2.2e}'.format(x).replace('e', 'x10^')\n",
    "\n",
    "#ax.set_ylim(21, 82)\n",
    "ax.set_ylim(0, 62)\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "date_form = DateFormatter(\"%H:%M\")\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "#fig.suptitle(\"Net energy usage forecasts (Year 4, Sep 2)\")\n",
    "fig.suptitle(\"Net energy usage forecasts (Year 4, Apr 15 - 16)\")\n",
    "ax.legend(bbox_to_anchor=(1,0), loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT * FROM forecast\" # LIMIT 10\"\n",
    "run_predictions = pd.read_sql(query_string, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "times = [(index2datetime(i), i+1, i+24) for i in indices]\n",
    "display(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload building data from csv to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    building_nr = 5\n",
    "    df = pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\").astype({'datetime': 'datetime64'})\n",
    "    df.index.name = \"id\"\n",
    "    \n",
    "    df.to_sql(\"building5\", con=db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adec6c5f7a7e6b374924807d676c9e580fd19dbf1c8cad640c4c5a1bb48bcada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
