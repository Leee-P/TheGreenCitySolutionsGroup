{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from datetime import datetime, timedelta\n",
    "from pydash import py_\n",
    "from green_city.utils import datetime2index, index2datetime\n",
    "\n",
    "from green_city.mlflow_config import get_mlflow_config\n",
    "mlflow.set_tracking_uri(get_mlflow_config()[\"TRACKING_URI\"])\n",
    "client = MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(\"green_city_experiments\").experiment_id\n",
    "\n",
    "## DB CONNECTION ##\n",
    "from sqlalchemy import create_engine\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "config = Config(RepositoryEnv(\"../.db_credentials\"))\n",
    "\n",
    "db_connection_credentials = {\n",
    "    \"database\": config('POSTGRES_DB'),\n",
    "    \"user\": config('POSTGRES_USER'),\n",
    "    \"password\": config('POSTGRES_PASSWORD'),\n",
    "    \"host\": config('POSTGRES_HOST'),\n",
    "    \"port\": config('POSTGRES_PORT'),\n",
    "}\n",
    "DB_STRING = \"postgresql://{user}:{password}@{host}:{port}/{database}\".format(**db_connection_credentials)\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [r.run_id for r in client.list_run_infos(experiment_id, run_view_type=ViewType.ACTIVE_ONLY)]\n",
    "\n",
    "all_runs = {run_id: client.get_run(run_id).to_dictionary() for run_id in run_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dict = {}\n",
    "\n",
    "for id, details in all_runs.items():\n",
    "    start_time = py_.get(details, \"info.start_time\")\n",
    "    end_time = py_.get(details, \"info.end_time\")\n",
    "    delta = round(end_time/1000 - start_time/1000, 2)\n",
    "    runs_dict[id] = {\n",
    "        \"time_s\": delta,\n",
    "        **py_.get(details, \"data.metrics\"),\n",
    "        **py_.get(details, \"data.params\"),\n",
    "        \"run_name\": details[\"data\"][\"tags\"][\"mlflow.runName\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(runs_dict, orient='index')\n",
    "df = df.astype({\"datetime\": \"datetime64[ns]\"})\n",
    "df = df.assign(index = df['index'].fillna(df.datetime.map(datetime2index))).dropna(subset=[\"index\"])\n",
    "\n",
    "#if index is not set, assign it from datetime\n",
    "df.datetime.map(datetime2index).unique()\n",
    "df = df.astype({\"index\": \"int\", \"train_steps\": \"float\"})\n",
    "df.index = df.index.rename(\"run_id\")\n",
    "\n",
    "#Drop the shorter TBATS models\n",
    "df = df[np.logical_or(np.logical_not(df.train_steps<1000), df.model!=\"TBATS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25, 8]\n",
    "df[df.feature==\"net_load_kWh\"].loc[:, [\"mae\", \"mse\", \"r2_score\"]].plot.barh()\n",
    "#df[df.feature==\"net_load_kWh\"].loc[:, [\"time_s\"]].plot.barh()\n",
    "df.to_csv(\"../data/results/evaluation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_label(df_row):\n",
    "    if df_row[\"model\"] == \"TBATS\":\n",
    "        if not np.isnan(df_row[\"train_steps\"]):\n",
    "            return df_row['model'] + \" (\" + str(int(df_row['train_steps'])) + \" trainsteps)\"\n",
    "        else:\n",
    "            return df_row['model']\n",
    "    elif df_row[\"model\"] == \"sarimax\":\n",
    "        return df_row[\"run_name\"].capitalize().replace(\"_\", \" \")\n",
    "    elif df_row[\"model\"] == \"baseline\":\n",
    "        return \"baseline (last year)\"\n",
    "    elif df_row[\"model\"] == \"linear_regression\":\n",
    "        return \"Linear regression\"\n",
    "    else:\n",
    "        return df_row[\"model\"]\n",
    "    \n",
    "\n",
    "df[\"disp_label\"] = df.apply(row_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "   \n",
    "model2color = {\n",
    "    \"baseline\": \"orange\",\n",
    "    \"linear_regression\": \"orange\",\n",
    "    \"TBATS\": \"blue\",\n",
    "    \"sarimax\": \"green\",\n",
    "}\n",
    "\n",
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "for index in indices:\n",
    "    fig = plt.figure()\n",
    "    plot_df = (df[df[\"index\"] == index]\n",
    "                .sort_values(\"mse\", ascending=False)\n",
    "                .assign(col = lambda x:x[\"model\"].map(lambda x: model2color.get(x, \"black\")))\n",
    "                #.assign(label = lambda x: f\"{x['model']}{steps2str(x['train_steps'])}\")\n",
    "    )\n",
    "    plot_df.plot.barh(x=\"disp_label\", y=\"mse\", color=plot_df[\"col\"], legend=None)\n",
    "    plt.xlabel(\"Mean squared error\")\n",
    "    plt.ylabel(None)\n",
    "    plt.suptitle(f\"{str(index2datetime(index+1))} to {str(index2datetime(index+24))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual dataset\n",
    "def get_df(building_nr, feature):\n",
    "    df = (\n",
    "    pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\")\n",
    "        .astype({'datetime': 'datetime64'})\n",
    "        [[feature, \"datetime\"]]\n",
    "        .rename(columns={feature: \"actual\"})\n",
    "    )\n",
    "    df.index.name = \"id\"\n",
    "    return df\n",
    "\n",
    "actual_df = get_df(5, \"net_load_kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25, 6]\n",
    "\n",
    "index_to_plot = indices[0]\n",
    "plot_df = df[df[\"index\"] == index_to_plot]\n",
    "plot_df\n",
    "\n",
    "y_true = actual_df.loc[index_to_plot+1-50:index_to_plot+24].set_index(\"datetime\")\n",
    "\n",
    "for run_id, run_data in plot_df.iterrows():\n",
    "    query_string = f\"SELECT * FROM forecast WHERE run_id='{run_id}'\" # LIMIT 10\"\n",
    "    run_predictions = pd.read_sql(query_string, db).drop(columns=\"run_id\")\n",
    "    run_predictions[\"datetime\"] = run_predictions[\"id\"].map(index2datetime)#y_true.index\n",
    "    color = model2color.get(run_data.model, \"gray\")\n",
    "    plt.plot(run_predictions.drop(columns=[\"id\"]).set_index(\"datetime\"), color=color)\n",
    "plt.plot(y_true, color=\"black\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT * FROM forecast\" # LIMIT 10\"\n",
    "run_predictions = pd.read_sql(query_string, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [32135, 33311, 26478, 33357, 30387, 30794, 31800, 28783]\n",
    "times = [(index2datetime(i), i+1, i+24) for i in indices]\n",
    "display(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload building data from csv to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    building_nr = 5\n",
    "    df = pd.read_csv(f\"../data/preprocessed/Building_{building_nr}.csv\").astype({'datetime': 'datetime64'})\n",
    "    df.index.name = \"id\"\n",
    "    \n",
    "    df.to_sql(\"building5\", con=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(index=[\"7db782fa0278400d808e9d29aac6ad4f\", \"8f2a6dc587a34e77a2691867ebf6bb08\"])\n",
    "#df.drop(index=[df.index[3]])\n",
    "df[np.logical_or(np.logical_not(df.train_steps<1000), df.model!=\"TBATS\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adec6c5f7a7e6b374924807d676c9e580fd19dbf1c8cad640c4c5a1bb48bcada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
